{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"STORASENSE - Welcome to our systems documentation!","text":""},{"location":"#team","title":"Team","text":"<ul> <li>Aleyna Cikrik</li> <li>Ruben Nessler</li> <li>Mario Di Caprio</li> <li>Paul Schr\u00f6ppel</li> </ul>"},{"location":"content/about/intro_goals/","title":"STORASENSE - PROJEKT\u00dcBERSICHT","text":""},{"location":"content/about/intro_goals/#einfuhrung-und-ziele","title":"Einf\u00fchrung und Ziele","text":"<p>Ziel des Projekts \"Storasense\" ist die Entwicklung eines softwaregest\u00fctzten \u00dcberwachungssystems zur kontinuierlichen Kontrolle der Umgebungsbedingungen in Lagerr\u00e4umen. Das System dient der Qualit\u00e4tssicherung und Verlustpr\u00e4vention bei der Lagerung verderblicher oder sensibler G\u00fcter, die spezifische klimatische Bedingungen erfordern.</p> <p>Der prim\u00e4re Anwendungsbereich umfasst die \u00dcberwachung von Lagern f\u00fcr wertvolle G\u00fcter \u2013 wie beispielsweise Lebensmittel oder Pharmazeutika - , deren Qualit\u00e4t von insbesondere folgenden Faktoren abh\u00e4ngig ist:</p> <ul> <li>Temperatur: Einhaltung eines konstanten, k\u00fchlen Niveaus. </li> <li>Luftfeuchtigkeit: Vermeidung von zu hoher oder zu niedriger Feuchtigkeit. </li> <li>Luftqualit\u00e4t: Sicherstellung einer reinen, insbesondere von Schadstoffen (Kohlenstoffdioxid) freien Umgebung. </li> <li>Weiter erfolgt die Kontrolle des Lagerraums im Zuge der \u00dcberwachung des Zustandes der Eingangst\u00fcr (offen / geschlossen).</li> </ul>"},{"location":"content/about/intro_goals/#funktionale-anforderungen-fachlichkeit","title":"Funktionale Anforderungen (Fachlichkeit)","text":"<p>Es gilt ein System zu entwickeln, das sowohl aus Hardware- als auch aus Software- Komponenten besteht, die ineinandergreifen.</p> <p>Sensorik (Hardware): Ein Netzwerk von IoT erfasst die physikalischen Messgr\u00f6\u00dfen alle 5 Sekunden. Folgende 5 Sensortypen werden unterst\u00fctzt:</p> <ul> <li>Temperatursensor (Innen): Messung der Raumteperatur.</li> <li>Temperatursensor (Au\u00dfen): Messung der Au\u00dfentemperatur.</li> <li>Luftfeuchtigkeitssensor: Erfassung der relativen Luftfeuchtigkeit.</li> <li>Luftqualit\u00e4tssensor: Detektion des Kohlenstoffdioxidgehaltes in der Luft.</li> <li>Ultraschallsensor: Zur \u00dcberpr\u00fcfung des Zustandes der T\u00fcr \u2013 ist die T\u00fcr offen oder geschlossen.</li> </ul> <p>Software-Plattform (Kernsystem): Eine zentrale Anwendung, f\u00fcr die Nutzer \u00fcber eine Weboberfl\u00e4che zugreifbar, die folgende Funktionalit\u00e4ten bereitstellt:</p> <ul> <li>Timeline-Dashboard: Permanente Speicherung und grafische Visualisierung aller alle 5 Sekunden ver\u00f6ffentlichter Sensorwerte. Insgesamt zeigt die Timeline je Sensor die Werte der letzen Stunde an.</li> <li>Historische Datenanalyse: Speicherung und Darstellung von Schl\u00fcsselwerten der Messdaten \u00fcber Zeit (beispielsweise Durchschnittswert der letzten 30 Tage), um Trends und Muster zu erkennen.</li> <li>Konfigurierbare Schwellenwerte / Festlegen eines Toleranzbereichs: Erm\u00f6glicht dem Akteur (Lagerverantwortlicher), f\u00fcr jeden Sensor individuelle Min/Max-Grenzwerte zu definieren.</li> <li>Automatisiertes Alarmsystem: Zeigt bei Grenzwertverletzungen (\"Alarm wird ausgel\u00f6st\") eine \u00dcbersicht der Grenzwertverletzung in der Software-Plattform an - innerhalb der n\u00e4chsten 90 Sekunden nach Alarmerkennung.</li> <li>Proaktive Gegensteuerung: Bei einem kritischen Ereignis (\"Alarm wurde ausgel\u00f6st\") sollen IoT-Ger\u00e4te bef\u00e4higt werden proaktiv auf den Misstand des Lagerortes reagieren zu k\u00f6nnen. Hierf\u00fcr sendet das System eine MQTT-Nachricht an ein dediziertes MQTT-Topic, worauf sich jene Aktoren (beispielsweise ein intelligentes K\u00fchlaggregat) abbonnieren k\u00f6nnen, um die Nachricht \u00fcber einen Alarm zu empfangen und automatisiert Gegenma\u00dfnahmen auszuf\u00fchren (zum Beispiel K\u00fchlaggregat aschalten).</li> <li>Nutzer: Das System verwaltet bis zu 500 Benutzer, die verschiedene Rollen einnehmen k\u00f6nnen - Admin / Contributor. Admins sind \"Hausherren\" eines Lagerortes und k\u00f6nnen alle Einstellungen vornehmen. Contributors haben nur Leserechte.</li> <li>Lagerorte: Das System bietet die Verwaltung von bis zu 500 Lagerorten an.</li> <li>Sensorik: Je Lagerort, l\u00e4sst sich jeweils einer der 5 definierten Sensortypen (s.o.) registrieren. Diese werden mit einem Min/Max-Schwellwert konfiguriert.  </li> </ul> ID Titel Beschreibung Akteure/Rollen Komponente Daten/Trigger Erfolgskriterium Qualit\u00e4ts-/Zeitbezug FR-1 Sensorerfassung 5s Ein Netzwerk von IoT-Sensoren erfasst alle 5 Sekunden Messwerte. 5 Sensortypen werden unterst\u00fctzt. Sensorger\u00e4te, System Hardware Sensorik Zeittrigger 5s Werte landen zuverl\u00e4ssig im System Kontinuit\u00e4t, Echtzeitn\u00e4he FR-1.1 Temp innen Messung der Raumtemperatur (Innen). Sensorger\u00e4t, System Hardware Sensorik Messzyklus 5s Wert verf\u00fcgbar Abdeckung Sensor-Typen FR-1.2 Temp au\u00dfen Messung der Au\u00dfentemperatur. Sensorger\u00e4t, System Hardware Sensorik Messzyklus 5s Wert verf\u00fcgbar Abdeckung Sensor-Typen FR-1.3 Luftfeuchte Erfassung der relativen Luftfeuchtigkeit. Sensorger\u00e4t, System Hardware Sensorik Messzyklus 5s Wert verf\u00fcgbar Abdeckung Sensor-Typen FR-1.4 Luftqualit\u00e4t CO\u2082 Detektion des CO\u2082-Gehaltes. Sensorger\u00e4t, System Hardware Sensorik Messzyklus 5s Wert verf\u00fcgbar Abdeckung Sensor-Typen FR-1.5 T\u00fcrstatus Ultraschall zur Erkennung \u201eT\u00fcr offen/geschlossen\u201c. Sensorger\u00e4t, System Hardware Sensorik Messzyklus 5s Wert verf\u00fcgbar Abdeckung Sensor-Typen FR-2 Timeline-Dashboard Permanentes Speichern und Visualisieren aller 5\u2011Sekunden\u2011Sensorwerte; Anzeige der letzten Stunde je Sensor. Admin, Contributor Software Plattform (Web - Dashboard) neue Messwerte Kurve/Verlauf pro Sensor sichtbar Visualisierungsnutzen, 1h Sicht FR-3 Historische Analyse Speicherung und Darstellung von Schl\u00fcsselwerten \u00fcber Zeit (z. B. Durchschnitt der letzten 30 Tage) zur Trend\u2011Erkennung. Admin, Contributor Software Plattform (Web - Analytics) Abfragen/Jobs Kennzahlen abrufbar Verst\u00e4ndliche Trends/Muster FR-4 Schwellenwerte Konfigurierbare Min/Max\u2011Grenzen je Sensor durch Lagerverantwortliche. Admin Software Plattform (Web - Sensors) Benutzeraktion Werte gespeichert und g\u00fcltig Korrekte Validierung/Anwendung FR-5 Alarmierung Bei Grenzwertverletzung Anzeige einer Alarm\u00fcbersicht innerhalb von 90 Sekunden nach Erkennung. Admin, Contributor Software Plattform (Web - Alarms) Schwellenverletzung Alarm sichtbar \u2264 90 s Reaktionszeit \u2264 90s FR-6 Proaktive Gegensteuerung Bei Alarm sendet das System eine MQTT\u2011Nachricht an ein dediziertes Topic; Aktoren k\u00f6nnen abonnieren und automatisiert reagieren (z. B. K\u00fchlung einschalten). Software Plattform / Aktorger\u00e4te Plattform/IoT\u2011Integration (MQTT) Alarmereignis MQTT\u2011Publish auf Topic Entkopplung, Ereignisgesteuert FR-7 Nutzerverwaltung Verwaltung bis zu 500 Benutzern mit Rollen Admin/Contributor; Admin volle Rechte, Contributor lesen. Admin Software Plattform (Web, IAM) Benutzeranlage/\u2011login Rollen greifen Skalierung Nutzer 500 FR-8 Lagerorte Verwaltung bis zu 500 Lagerorten. Admin Software Plattform (Web - Storages) Anlage/Verwaltung Orte angelegt/auffindbar Skalierung Orte 500 FR-9 Sensor je Lagerort Je Lagerort Registrierung eines der 5 Sensortypen inkl. Min/Max\u2011Schwellwert\u2011Konfiguration. Admin Software Plattform (Web - Sensors) - - -"},{"location":"content/about/intro_goals/#use-case-szenarien","title":"Use-Case-Szenarien","text":"<p>Die folgenden Szenarien beschreiben beispielhaft die wichtigsten Anwendungsf\u00e4lle des Systems:</p>"},{"location":"content/about/intro_goals/#primarer-use-case-kontinuierliche-uberwachung-im-normalbetrieb","title":"Prim\u00e4rer Use-Case: Kontinuierliche \u00dcberwachung im Normalbetrieb","text":"Phase Beschreibung Vorbedingungen Das System ist online und eingestellt. Die Schwellenwerte f\u00fcr alle Sensoren sind konfiguriert. Ablauf 1. Die Sensoren erfassen alle 5 Sekunden die Umgebungsdaten.2. Die Daten werden an die zentrale Software-Plattform \u00fcbertragen.3. Die Plattform validiert die Daten und vergleicht sie kontinuierlich mit den hinterlegten Schwellwerten.4. Solange alle Messwerte innerhalb der definierten Toleranzbereiche liegen, protokolliert das System die Daten und l\u00f6st kein Alarmereignis aus. Nachbedingungen Die Qualit\u00e4t der gelagerten G\u00fcter bleibt gesichert."},{"location":"content/about/intro_goals/#sekundarer-use-case-abweichung-und-alarmierung","title":"Sekund\u00e4rer Use-Case: Abweichung und Alarmierung","text":"Phase Beschreibung Trigger Ein Sensor meldet einen Messwert, der einen konfigurierten Schwellenwert \u00fcber- oder unterschreitet \\(z\\.B\\. Temperatur &gt; 18 \u00b0C\\). Ablauf 1. Das System identifiziert die Grenzwertverletzung und klassifiziert das Ereignis als Alarm.2. Ein Alarmereignis wird ausgel\u00f6st und es passieren ggf. folgende zwei Aktionen:\u00a0\u00a01. Das System versendet sofort eine \u00dcbersicht \u00fcber das Alarmereignis an die Weboberfl\u00e4che, wo sie alle Mitglieder eines Lagerortes einsehen k\u00f6nnen.  Die Nachricht enth\u00e4lt: den betroffenen Sensor, eine kurze Nachricht mit Messwert und wann die Verletzung festgestellt wurde .\u00a0\u00a02. Das System sendet eine MQTT-Nachricht an das MQTT-Topic. Ein auf das Topic abonnierter Aktor, z.B. ein IoT-Ger\u00e4t, k\u00f6nnte daraufhin eine Gegenma\u00dfnahme ausf\u00fchren.3. Der verantwortliche Akteur sieht die Nachricht im Dashboard, analysiert die Situation und leitet Gegenma\u00dfnahmen ein.4. Nach Behebung der Ursache kann der Akteur den Alarm im System entfernen. Nachbedingungen Der potenzielle Schaden an den Lagerg\u00fctern wurde durch rechtzeitige Intervention verhindert. Der Vorfall ist f\u00fcr sp\u00e4tere Analysen dokumentiert."},{"location":"content/about/intro_goals/#stakeholder","title":"Stakeholder","text":"Stakeholder Beschreibung Kunde - Eigent\u00fcmer eines Lagerortes (\"Admin\") - verantwortlich f\u00fcr Installation, Konfiguration und Wartung des Systems f\u00fcr seinen Lagerort.  - Kann mehrere Lagerorte verwalten   - Verwaltet die Nutzer und Sensoren eines Lagerortes und nutzt die Daten (Dashboard, Analytics, Alarms) f\u00fcr Prozessoptimierung, Qualit\u00e4tsaudits und Eingriffe.  - Kann Mitglieder, also weitere Nutzer (\"Contributor\"), seinem Lagerort hinzuf\u00fcgen.  - Contributor haben lesenden Zugriff auf alle Daten eines Lagerorts und k\u00f6nnen darauf basierend ebenso die Daten f\u00fcr Prozessoptimierung, Qualit\u00e4tsaudits und Eingriffe nutzen.  - Kann Aktore (z.B. IoT-Ger\u00e4te) auf das MQTT-Topic subscriben, um automatisiert auf Alarme zu reagieren. Contributor - Hinzugef\u00fcgte Nutzer mit Leserechten je Lagerort.  - Erwartet konsistente Visualisierung, klare Historien/Trends und nachvollziehbare Alarme.  - Erwartet stabile Weboberfl\u00e4che und performante Abfragen ohne Schreibrechte. Entwicklungsteam - Sind am Projekterfolg interessiert. Dieser setzt die Umsetzung der zuvor definierten funktionalen und nicht funktionalen Anforderungen vorraus."},{"location":"content/about/intro_goals/#qualitatsziele","title":"Qualit\u00e4tsziele","text":"<p>Es lassen sich folgende Qualit\u00e4tsziele, gest\u00fctzt durch Qualit\u00e4tsszenarien, definieren:</p>"},{"location":"content/about/intro_goals/#nfr-1-erweiterbarkeit-der-software-plattform","title":"NFR-1 Erweiterbarkeit der Software-Plattform","text":""},{"location":"content/about/intro_goals/#szenario-1-erweiterung-des-platform-teilsystems-monitoring","title":"Szenario 1: Erweiterung des Platform-Teilsystems \u201eMonitoring\u201c","text":"<p>Dieses Szenario definiert die F\u00e4higkeit, die Funktionalit\u00e4t des bestehenden \u00dcberwachungssystems zu erweitern, ohne das Kernsystem zu ver\u00e4ndern. Ein typischer Fall ist die Anbindung eines neuen Sensortyps.</p> Attribut Beschreibung Szenarioname Erweiterung \u00dcberwachungssystem Quelle Kernentwickler / Externer Entwickler Stimulus Es besteht die Anforderung, einen neuen, bisher nicht unterst\u00fctzten Sensortyp in das System zu integrieren. Artefakt Das System \u201e\u00dcberwachung\u201c Umgebung System befindet sich in der Entwicklung / Wartung Reaktion Die Software-Architektur des Monitoring-Teilsystems erm\u00f6glicht die Anbindung des neuen Sensortyps. Bestehende Funktionen (wie die Verarbeitung der Daten von Temperatur- oder Feuchtigkeitssensoren) bleiben davon unber\u00fchrt und funktionieren weiterhin korrekt. Reaktionsma\u00df Die Integration des neuen Sensortyps (inklusive Datenverarbeitung, Speicherung und Visualisierung) ist von einem Entwickler innerhalb von sieben Tagen ohne Regressionsfehler in anderen Teilen des Systems umsetzbar."},{"location":"content/about/intro_goals/#szenario-2-erweiterung-der-plattform-um-neue-teilsysteme","title":"Szenario 2: Erweiterung der Plattform um neue Teilsysteme","text":"<p>Dieses Szenario beschreibt die Erweiterbarkeit der gesamten Plattform-Architektur. Das Ziel ist es, komplett neue Funktionalit\u00e4tsbl\u00f6cke als eigenst\u00e4ndige Teilsysteme hinzuzuf\u00fcgen, wie zum Beispiel eine dedizierte \"Anleitungsbibliothek\" je Lagerort. Dabei soll bestehende zentrale Funkktionalit\u00e4t wiederverwendet werden.</p> Attribut Beschreibung Szenarioname Erweiterung Plattform Quelle Kernentwickler / Externer Entwickler Stimulus Die Plattform soll um ein neues Teilsystem \"Anleitungsbibliothek\" erweitert werden, das es Nutzern erm\u00f6glicht, Handlungsanweisungen zu hinterlegen und abzurufen. Artefakt Die gesamte Software-Plattform, insbesondere ihre Kernarchitektur und die definierten Schnittstellen. Umgebung System befindet sich in der Weiterentwicklung Reaktion Die Plattform-Architektur stellt klar definierte Erweiterungspunkte beziehungsweise eine offene API bereit.Das neue Teilsystem kann als eigenst\u00e4ndiges Modul oder Service entwickelt und in die Plattform integriert werden, ohne den Code der bestehenden Teilsysteme zu modifizieren.Bestehende Plattformlogik (z.B. Benutzerverwaltung) wird wiederverwendet bzw. integriert. Reaktionsma\u00df Das neue Teilsystem kann ohne Ausfallzeit des Gesamtsystems (\"Zero Downtime Deployment\") in Betrieb genommen werden.Der Entwicklungsaufwand f\u00fcr die reine Integration (Anbindung an die zentrale Navigation, Benutzerverwaltung, etc.) betr\u00e4gt weniger als eine Woche."},{"location":"content/about/intro_goals/#nfr-2-performance-der-alarmierung","title":"NFR-2 Performance der Alarmierung","text":""},{"location":"content/about/intro_goals/#szenario-alarmierungszeit-90-sekunden-ab-detektion-der-grenzwertuberschreitung","title":"Szenario: Alarmierungszeit \u2264 90 Sekunden ab Detektion der Grenzwert\u00fcberschreitung","text":"<p>Ein rasches \u00dcberschreiten oder Unterschreiten definierter Schwellenwerte der Umgebungsparameter \u2013 wie Temperatur, oder Luftfeuchtigkeit \u2013 kann potenziell erhebliche Sch\u00e4den verursachen. Ziel des Alarmierungssystems ist es daher, eine zust\u00e4ndige Entit\u00e4t (z.B. eine Nutzerperson oder ein autonom agierendes IoT-System) innerhalb k\u00fcrzester Zeit - 90 Sekunden nach Detektion eines individuellen Ausrei\u00dfer-Messwertes - zu informieren, um pr\u00e4ventive oder mitigierende Ma\u00dfnahmen einzuleiten.</p> <p>Das Informieren erfolgt dabei dual:</p> <ul> <li>Web-UI in der Software-Plattform, die alle Mitglieder eines Lagerortes einsehen k\u00f6nnen</li> <li>MQTT-Nachricht an ein MQTT-Topic zur automatisierten Weiterverarbeitung durch angeschlossene Systeme</li> </ul> Attribut Beschreibung Szenarioname Schnelles Alarmierungssystem Quelle Sensorik / Arduino / Software-Plattform (z.B. App) Stimulus Gemessener individueller Messwert verletzt den festgelegten Toleranzbereich. Artefakt Arduino mit Sensorik, Die Software inklusive Web-UI und MQTT-Publisher. Umgebung Das System befindet sich im produktiven Normalbetrieb. Reaktion Durch kontinuierliche Daten\u00fcbertragung kann schnell ein abnormaler Zustand detektiert werden. Daraufhin werden betreffende Entit\u00e4ten alarmiert \u2013 Nutzer und ggf. weitere Systeme. Reaktionsma\u00df Nach Detektion wird innerhalb von 90 Sekunden sowohl ein Alarm in der Web-UI dargestellt, als auch eine MQTT-Nachricht versendet."},{"location":"content/about/intro_goals/#nfr-3-sicherheit","title":"NFR-3 Sicherheit","text":""},{"location":"content/about/intro_goals/#szenario-sichere-authentifizierung-und-autorisierung","title":"Szenario: Sichere Authentifizierung und Autorisierung","text":"<p>Dieses Szenario stellt sicher, dass sich beliebige Personen selbst registrieren k\u00f6nnen, aber nach Anmeldung nur die Aktionen und Daten sehen d\u00fcrfen, die ihren zugewiesenen Rollen je Lagerort (\u201eAdmin\u201c, \u201eContributor\u201c) entsprechen; nicht zugewiesene Lagerorte mit ihren zugeh\u00f6rigen Daten (z.B. Messwerte der Sensoren eines Lagerorts) bleiben strikt unzug\u00e4nglich.</p> Attribut Beschreibung Szenarioname Authentifizierungs- / Autorisierungs- Service mit Rollensystem Quelle Ein registrierter Nutzer (z.B. ein Admin oder Contributor). Stimulus Der Nutzer versucht, sich \u00fcber die Login-Maske der Plattform am System anzumelden, um auf das Dashboard zuzugreifen oder Konfigurationen vorzunehmen. Artefakt Authentifizierungs-, Autorisierungs-Service der Software-Plattform. Umgebung Das System befindet sich im produktiven Normalbetrieb. Reaktion Das System validiert die eingegebenen Anmeldedaten (Benutzername und Passwort) gegen die hinterlegte Datenbank. Bei erfolgreicher Authentifizierung gew\u00e4hrt das System dem Nutzer Zugriff entsprechend seiner zugewiesenen Lagerote und zugewiesenen Rollen (Lesezugriff f\u00fcr einen Contributor, Vollzugriff f\u00fcr einen Admin). Reaktionsma\u00df Die Anmeldung eines Nutzers erfolgt in weniger als 30 Sekunden."},{"location":"content/about/intro_goals/#nfr-4-verfugbarkeit","title":"NFR-4 Verf\u00fcgbarkeit","text":""},{"location":"content/about/intro_goals/#szenario-1-fehlertoleranz-und-automatische-wiederherstellung","title":"Szenario 1: Fehlertoleranz und automatische Wiederherstellung","text":"<p>Kritische Lagerbedingungen erfordern ein System, das m\u00f6glichst durchg\u00e4ngig verf\u00fcgbar ist, um eine l\u00fcckenlose \u00dcberwachung sicherzustellen. Falls das System \u00fcber einen l\u00e4ngeren Zeitraum nicht verf\u00fcgbar ist, ist der Zustand des Lagerguts unbekannt, und es k\u00f6nnten unbemerkte Sch\u00e4den entstehen, wenn beispielsweise eine Temperaturschwelle \u00fcberschritten wird.</p> Attribut Beschreibung Szenarioname System-Resilienz Quelle Ein interner Fehlerzustand Stimulus Ein unerwarteter Ausfall einer kritischen Komponente, z.B. der Absturz der Server-Anwendung, ein \"Einfrieren\" des Mikrocontrollers oder ein tempor\u00e4rer Verlust der Netzwerkverbindung. Artefakt Die gesamte Systeminfrastruktur: Sensor-Einheit (Hardware), Software-Plattform (Backend) und die Kommunikationskan\u00e4le. Umgebung Das System befindet sich im produktiven Normalbetrieb. Reaktion Das System leitet automatisch Ma\u00dfnahmen zur Wiederherstellung der vollen Funktionsf\u00e4higkeit ein. Diese Ma\u00dfnahmen umfassen insbesondere:- Automatisierte Neustarts: Software-Dienste werden durch Prozess-Manager (z.B. systemd) und Mikrocontroller durch Hardware-Watchdog-Timer bei einem Absturz sofort neu gestartet.- Robuste Wiederverbindungslogik: Das System versucht bei einem Verbindungsabbruch (z.B. zum WLAN oder MQTT-Broker) proaktiv und in regelm\u00e4\u00dfigen Intervallen, die Verbindung wiederherzustellen.- Zustands\u00fcberwachung (Health Check): Intern l\u00e4sst sich der Zustand der Anwendung \u00fcberpr\u00fcfen. Reaktionsma\u00df Kritische Systemkomponenten stellen ihre Funktionsf\u00e4higkeit nach einem behebbaren Ausfall automatisch und ohne manuellen Eingriff wieder her.Ein Administrator wird \u00fcber den Vorfall und die erfolgreiche Wiederherstellung informiert."},{"location":"content/about/intro_goals/#szenario-2-99-systemverfugbarkeit","title":"Szenario 2: 99% Systemverf\u00fcgbarkeit","text":"<p>Das System ist im produktiven Einsatz. Das folgende Szenario zeigt die im Szenario 1 beschriebene Ma\u00dfnahme zur automatischen Wiederherstellung und Fehlertoleranz.</p> Attribut Beschreibung Szenarioname Systemverf\u00fcgbarkeit Quelle Ein interner Fehlerzustand Stimulus Das System st\u00fcrzt w\u00e4hrend des laufenden Betriebs ab, w\u00e4hrend Umweltdaten erfasst werden. Artefakt Die Serveranwendungen, die MQTT-Nachrichten verarbeitet und Daten speichert. Umgebung Das System befindet sich im produktiven Normalbetrieb. Reaktion Der Absturz wird erkannt. Innerhalb weniger Sekunden erfolgen bis zu drei automatische Neustartversuche. Gelingt ein Neustart, werden MQTT-Client und Datenbankverbindung reinitialisiert. Daten gehen nicht verloren, falls das Backend (FastAPI App) abst\u00fcrzt. Die Anzeige im Dashboard wird nach kurzer Unterbrechung automatisch aktualisiert. Reaktionsma\u00df Die Anwendung ist innerhalb von 90 Sekunden wieder voll funktionsf\u00e4hig, ein manuelles Eingreifen ist nicht erforderlich. Die durchg\u00e4ngige Verf\u00fcgbarkeit bleibt erhalten - die Ausfallzeit liegt unterhalb der zul\u00e4ssigen 1% in einem Zeitraum von 72 Stunden. Daten, die w\u00e4hrend des Absturzes des Backends (FastAPI App) aufgezeichnet wurden, werden nachgereicht."},{"location":"content/about/intro_goals/#einflussfaktoren","title":"Einflussfaktoren","text":""},{"location":"content/about/intro_goals/#technisch","title":"Technisch","text":"<ul> <li>Hardware: Arduino-Mikrocontroller mit f\u00fcnf angeschlossenen Sensoren, die folgende Daten liefern: Temperaturmesswert, Luftfeuchtigkeitsmesswert, Kohlenstoffdioxidmesswert, Ultraschallabstandswert.</li> <li>Gestellter MQTT-Broker nach Publisher/Subscriber-Muster.</li> </ul>"},{"location":"content/about/intro_goals/#organisatorisch","title":"Organisatorisch","text":"<ul> <li>Entwicklungszeit: ~2 Monate</li> <li>Teamgr\u00f6\u00dfe: 4 Personen</li> <li>Scrum: 1-w\u00f6chiger Sprintrhythmus</li> </ul>"},{"location":"content/arc/arc/","title":"Architektur","text":""},{"location":"content/arc/arc/#ubersicht-deployment","title":"\u00dcbersicht (Deployment)","text":"Komponente Technologie Aufgabe &amp; Verantwortung Kommuniziert mit Client (Webbrowser) Standard-Webbrowser Stellt die Benutzeroberfl\u00e4che (das Dashboard) dar, die vom Frontend-Server geliefert wird. Erm\u00f6glicht dem Benutzer die Interaktion mit dem System (Daten ansehen, Einstellungen \u00e4ndern). Frontend IoT-Mikrocontroller (Arduino) Hardware (Arduino) mit MQTT-Bibliothek Erfasst die physischen Messwerte (z.B. Temperatur, Feuchtigkeit) und sendet diese als Nachrichten an den MQTT-Broker. Ist die prim\u00e4re Datenquelle. MQTT Broker Server-Infrastruktur Physischer/Virtueller Server mit Docker Engine Dient als Host-System, das alle Anwendungscontainer ausf\u00fchrt und verwaltet. Stellt die notwendigen Ressourcen wie CPU, RAM, ... bereit. \u2013 (Verwaltet alle Container) Frontend Next.js (React-Framework) Liefert die Benutzeroberfl\u00e4che an den Browser des Clients. Fragt Daten \u00fcber die API des Backends ab und visualisiert sie. Sendet Benutzeraktionen an das Backend. Client (Webbrowser), Backend Backend FastAPI (Python-Framework) Ist das \"Gehirn\" der Anwendung. Stellt eine REST-API f\u00fcr das Frontend bereit, nimmt weitergeleitete Sensordaten entgegen, validiert diese, pr\u00fcft auf Alarmbedingungen, speichert Daten in der Datenbank und sendet Alarme. Frontend, MQTT Client, TimescaleDB, MQTT Broker MQTT Client Python-Skript Dient als reiner Daten-Weiterleiter. Abonniert die Sensor-Topics beim Broker, empf\u00e4ngt die Rohdaten und schickt sie per HTTP-Request zur Verarbeitung an das Backend. Entkoppelt das Backend von der direkten MQTT-Kommunikation. MQTT Broker, Backend TimescaleDB PostgreSQL-Datenbank mit TimescaleDB-Erweiterung Ist der persistente Datenspeicher des Systems. Speichert sowohl die Zeitreihendaten der Sensoren (optimiert durch TimescaleDB) als auch die relationalen Daten (Benutzer, Lagerorte etc.). Backend MQTT Broker MQTT-Broker-Software Fungiert als zentrale Nachrichten-Drehscheibe f\u00fcr die Echtzeitkommunikation. Empf\u00e4ngt die Daten von den IoT-Ger\u00e4ten und verteilt sie an alle Abonnenten (hier: den MQTT Client). Nimmt zudem Alarme vom Backend entgegen. IoT-Ger\u00e4t, MQTT Client, Backend Docker Compose Network Docker Networking Ist ein virtuelles, privates Netzwerk. Erm\u00f6glicht den Containern eine sichere und einfache Kommunikation untereinander \u00fcber deren Service-Namen, ohne dass jeder Container-Port nach au\u00dfen freigegeben werden muss. \u2013 (Erm\u00f6glicht die Kommunikation zwischen den Containern)"},{"location":"content/arc/arc/#architekturentscheidung-entkopplung-von-backend-und-frontend","title":"Architekturentscheidung: Entkopplung von Backend und Frontend","text":"<p>Das System ist nach dem Prinzip einer entkoppelten Architektur konzipiert, bei der eine klare Trennung bzw lose Kopplung [1] zwischen der Benutzeroberfl\u00e4che (Frontend) und der serverseitigen Gesch\u00e4ftslogik (Backend) besteht.</p> <ul> <li> <p>Frontend (Client-Seite): Das Frontend, realisiert mit dem Next.js-Framework, ist ausschlie\u00dflich f\u00fcr die Darstellung und die Benutzerinteraktion verantwortlich. Seine einzige Aufgabe ist es so, dem Benutzer eine intuitive Oberfl\u00e4che zu bieten und Daten \u00fcber eine standardisierte Schnittstelle vom Backend abzurufen bzw. Aktionen dorthin zu senden.</p> </li> <li> <p>Backend (Server-Seite): Das Backend, entwickelt mit dem FastAPI-Framework, fungiert als zentrales Gehirn der Anwendung. Es stellt eine klar definierte REST-API bereit, \u00fcber die alle Datenoperationen und Gesch\u00e4ftslogiken abgewickelt werden. Es ist zust\u00e4ndig f\u00fcr die Authentifizierung von Benutzern, die Verarbeitung von Daten, die Kommunikation mit der Datenbank und die Implementierung des Alarmsystems.</p> </li> </ul> <p>Die Kommunikation zwischen diesen beiden Komponenten erfolgt zustandslos \u00fcber HTTP-Anfragen und das Backend liefert Antworten im JSON-Format.</p> <p>Durch diese strikte Trennung k\u00f6nnen beide Teile des Systems unabh\u00e4ngig voneinander entwickelt, getestet, aktualisiert und skaliert werden, ohne dass \u00c4nderungen am einen Teil zwangsl\u00e4ufig Anpassungen am anderen erfordern.</p>"},{"location":"content/arc/arc/#architekturentscheidung-seperater-mqtt-client-als-daten-weiterleiter","title":"Architekturentscheidung: Seperater MQTT-Client als Daten-Weiterleiter","text":"<p>Der MQTT-Client ist als separater, vom eigentlichen FASTAPI-Backend losgel\u00f6ster Dienst implementiert. Diese Entscheidung wurde getroffen, um die Architektur des Systems zu vereinfachen und die Verantwortlichkeiten nach dem Prinzip der Separation of Concerns [1] klar zu trennen.</p> <p>Das FastAPI-Backend wurde bewusst als schlanke \"Challenge-Response-Einheit\" konzipiert, deren prim\u00e4re Aufgabe es ist, auf zustandslose HTTP-Anfragen (Challenges) mit einer direkten Antwort (Response) zu reagieren. Ein MQTT-Client hingegen ist ein asynchroner, langlebiger Prozess, der eine permanente Verbindung h\u00e4lt und auf unvorhersehbare, von au\u00dfen initiierte Ereignisse (Nachrichten) reagieren muss. Die Integration dieser langlebigen, zustandsbehafteten Aufgabe in die Kernprozesse eines stateless API-Backends w\u00fcrde dessen Designphilosophie verletzen und zu einer unn\u00f6tigen Komplexit\u00e4t f\u00fchren.</p> <p>In diesem Entwurf agiert der MQTT-Client als Messaging Gateway [2], dessen einzige Verantwortung es ist, Nachrichten aus einem Messaging-System (MQTT) in einen f\u00fcr das Kernsystem verst\u00e4ndlichen Aufruf (HTTP-Request) zu \u00fcbersetzen.</p> <p>Weiter l\u00e4sst sich mit dieser Architektur die Anforderung nach einer hohen Verf\u00fcgbarkeit besser umsetzen: in Neustart oder Ausfall des Backends unterbricht nicht den Empfang der MQTT-Nachrichten (der Client verf\u00fcgt \u00fcber eine Retry-Logik), und umgekehrt beeinflusst ein Fehler im MQTT-Client nicht die Verf\u00fcgbarkeit der API f\u00fcr das Frontend. Die klaren Grenzen zwischen den Diensten erleichtern zudem die Wartung und ggf eine unabh\u00e4ngige Skalierung der Komponenten.  Ein weiterer Vorteil hinsichtlich der Performance wird im Zuge der Betrachtung des konkreten Ablaufs ersichtlich.</p>"},{"location":"content/arc/arc/#sequenzablauf-data-flow-erzeugung-ingestion-speicherung-alarmierung","title":"Sequenzablauf - Data-Flow: Erzeugung -&gt; Ingestion -&gt; Speicherung, Alarmierung","text":"<p>Folgendes Sequenzdiagramm zeigt den grunds\u00e4tzlichen funktionalen Ablauf des Systems:</p> <p></p> <p>Ein weitere Anforderung, die durch die Architektur gef\u00f6rdert wird ist die Performance-Qualit\u00e4tseigenschaft hinsichtlich Erkennung und Alarmierung bei kritischen Sensorwerten.  Sobald ein neuer Messwert vom MQTT-Client an das Backend \u00fcbermittelt wird, wird dieser unmittelbar und ohne Verz\u00f6gerung an den zust\u00e4ndigen Alarm-Service zur \u00dcberpr\u00fcfung weitergeleitet. Die Pr\u00fcfung auf Grenzwertverletzungen erfolgt somit, auch wenn die Daten noch nicht in der Datenbank gespeichert sind (das persistente Speichern erfolgt parallel).  Durch diese bewusste Priorisierung wird die Latenz der Alarmierung von der Latenz des Datenbank-Schreibvorgangs entkoppelt. Das System muss nicht auf die Best\u00e4tigung der Persistenz warten, um einen m\u00f6glichen kritischen Zustand zu erkennen und darauf zu reagieren.</p>"},{"location":"content/arc/arc/#bausteinsicht-fastapi-backend-wip","title":"Bausteinsicht: FastAPI-Backend [WIP!!]","text":""},{"location":"content/arc/arc/#grundsatzlich-kriterien","title":"Grunds\u00e4tzlich (Kriterien)","text":""},{"location":"content/arc/arc/#modularisierung-separation-of-concerns","title":"Modularisierung (Separation of Concerns)","text":"<ul> <li>Backend-System wird in sich geschlossene Bausteine zerlegt, die jeweils eine bestimmte Funktionalit\u00e4t bereitstellen (Serparation of Concerns)</li> <li>Module sollten in sich geschlossene, in sich konsistente Einheiten sein - die leicht entfernbar oder austauschbar sind (\"plug and play\")</li> </ul>"},{"location":"content/arc/arc/#lose-kopplung","title":"Lose Kopplung","text":"<ul> <li>Module sollten m\u00f6glichst unabh\u00e4ngig voneinander sein</li> </ul>"},{"location":"content/arc/arc/#geheimnisprinzip-abstraktion","title":"Geheimnisprinzip, Abstraktion","text":"<ul> <li>Module sollten m\u00f6glichst wenig Wissen \u00fcber andere Module haben</li> <li>Module sollten nur \u00fcber klar definierte Schnittstellen bzw Abstraktionen miteinander kommunizieren</li> </ul>"},{"location":"content/arc/arc/#hohe-konsistenz-der-module-konzeptuelle-integritat","title":"Hohe Konsistenz der Module =&gt; Konzeptuelle Integrit\u00e4t","text":"<ul> <li>Module sollten \u00e4hnliche Strukturen und Konventionen verwenden (\u00e4hnliche Problem \u00e4hnlich l\u00f6sen)</li> </ul>"},{"location":"content/arc/arc/#pattern-techniken","title":"Pattern / Techniken","text":""},{"location":"content/arc/arc/#principles","title":"Principles:","text":""},{"location":"content/arc/arc/#solid-open-closed-principle-ocp","title":"SOLID: Open-Closed Principle (OCP)","text":""},{"location":"content/arc/arc/#solid-dependency-inversion-principle-dip","title":"SOLID: Dependency Inversion Principle (DIP)","text":"<ul> <li>durchg\u00e4ngig einhalten, zwischen MODULES und zwischen MODULES-SHARED_STUFF</li> <li>ggf. mit Dependency Injection realisiert (Depdency Injector verwaltet die Instanz der abstrakten Klassen)</li> </ul> <p>Quellen:</p> <ul> <li>[1] Starke, G. (2024). Effektive Softwarearchitektur: Ein praktischer Leitfaden. Hanser Verlag. 48ff</li> <li>[2] Enterprise Integration Patterns - Messaging Patterns</li> </ul>"},{"location":"content/arc/data_eva/","title":"Datendom\u00e4ne","text":""},{"location":"content/arc/data_eva/#datenmodellierung-konzeptuell","title":"Datenmodellierung (Konzeptuell)","text":"<p>Vor der Auswahl einer spezifischen Datenbanktechnologie wird das fachliche Datenmodell definiert, das alle f\u00fcr das System STORASENSE relevanten Informationen und deren Beziehungen zueinander abbildet. Diese ergeben sich aus den definierten Anforderungen.  Insgesamt basiert das Modell auf f\u00fcnf Entit\u00e4ten:</p> <ul> <li>User: Stellt eine Person dar, die mit dem System interagiert. Ein Benutzer beinhaltet folgende Attribute:</li> <li>ID: Eine eindeutige ID des Benutzers</li> <li>Username: Ein eindeutiger Benutzername</li> <li>Passwort: Ein Passwort (mit Hashing)</li> <li>Rolle: Eine Rolle, die den Zugriff auf ein Lagerort einschr\u00e4nkt</li> <li>Beschreibung: Eine optionale Beschreibung des Benutzers</li> <li>Lagerorte: Referenzen auf zugegriffene Lagerorte  </li> <li>Storage: Repr\u00e4sentiert einen physischen Ort (z.B. \"Weinkeller A\", \"Lagerhalle B\"), der \u00fcberwacht wird. Jeder Lagerort besitzt eindeutige Attribute wie eine ID und einen Namen. Ein Lagerort beinhaltet folgende Attribute:</li> <li>ID: Eine eindeutige ID des Lagerorts</li> <li>Name: Ein eindeutiger Name des Lagerorts (z.B. \"Weinkeller A\")</li> <li>Beschreibung: Eine optionale Beschreibung des Lagerorts</li> <li>Nutzer: Referenzen auf Nutzer, die auf den Lagerort Zugriff haben  </li> <li>Sensor: Stellt einen physischen Sensor dar, der Messwerte erfasst. Ein Sensor beinhaltet folgende Attribute:</li> <li>ID: Eine eindeutige ID des Sensors</li> <li>Typ: Der Typ des Sensors (z.B. Temperatur, Luftfeuchtigkeit)</li> <li>Min &amp; Max: Grenzwerte f\u00fcr den Sensor</li> <li>Lagerort: Eine Referenz auf den Lagerort, an dem sich der Sensor befindet  </li> <li>Measurement: Repr\u00e4sentiert eine einzelne, zu einem exakten Zeitpunkt erfasste Messung (z.B. Temperatur, Luftfeuchtigkeit). Ein Messwert beinhaltet folgende Attribute:</li> <li>ID: Eine eindeutige ID der Messung</li> <li>Erstellungszeit: Der genaue Zeitpunkt der Messung</li> <li>Wert: Der gemessene Wert</li> <li>Einheit: Die Einheit des Messwertes (z.B. Temperatur in \u00b0C, Luftfeuchtigkeit in %)</li> <li>Sensor: Eine Referenz auf den Sensor, der die Messung entnommen hat  </li> <li>Alert: Repr\u00e4sentiert einen Alarm, der ausgel\u00f6st wird, wenn ein Messwert au\u00dferhalb eines definierten Schwellenwerts liegt. Ein Alarm beinhaltet folgende Attribute:</li> <li>ID: Eine eindeutige ID des Alarms</li> <li>Beschreibung: Eine beschreibung des Alarms (z.B. \"Temperatur zu hoch\")</li> <li>Schweregrad: Der Schweregrad des Alarms (z.B. \"hoch\", \"mittel\", \"niedrig\")</li> <li>Messung: Eine Referenz auf die Messung, die den Alarm ausgel\u00f6st hat </li> </ul>"},{"location":"content/arc/data_eva/#datenvolumen","title":"Datenvolumen","text":"<p>Das erwartete Datenvolumen ist moderat, da das System in erster Linie Echtzeitdaten von Sensoren erfasst und speichert.</p>"},{"location":"content/arc/data_eva/#datenmenge","title":"Datenmenge","text":""},{"location":"content/arc/data_eva/#measurement","title":"Measurement:","text":"<p>Wie eingangs im Projekt\u00fcberblick beschrieben, besteht die Sensorik des Systems aus vier Sensoren die t\u00e4glich f\u00fcr 2.5 Monate alle 30 Sekunden Messwerte erfassen. Folgende Rechnung verdeutlicht die erwartete Datenmenge:</p> <ul> <li>Anzahl der Sensoren: 4</li> <li>Jeder Sensor sendet alle 30 Sekunden einen Messwert.</li> <li>Das ergibt:</li> <li>Messungen pro Stunde pro Sensor: (60/30) x 60 = 120</li> <li>Messungen pro Tag pro Sensor: 120 x 24 = 2.880</li> <li>Messungen pro Tag gesamt (4 Sensoren): 2.880 x 4 = 11.520</li> <li>Messungen f\u00fcr 2,5 Monate (ca. 75 Tage): 11.520 x 75 = 864.000 Messpunkte</li> </ul> <p>Insgesamt werden also ca. 864.000 Messpunkte erwartet, die in der Datenbank gespeichert werden m\u00fcssen.</p>"},{"location":"content/arc/data_eva/#weitere-entitaten","title":"Weitere Entit\u00e4ten:","text":"<p>Die weiteren Entit\u00e4ten haben eine deutlich geringere Anzahl an Instanzen:</p> <ul> <li>Wie bereits im Projekt\u00fcberblick beschrieben unterst\u00fctzt das System bis zu 500 Benutzer und 50 Lagerorte.</li> <li>Weiter sind 2 Rollen vorgesehen, die den Benutzern zugeordnet werden k\u00f6nnen.</li> <li>Die letzten 500 Alarme eines Lagerorts werden ebenfalls gespeichert. So ergibt sich eine maximale Anzahl von 25.000 Alarm-Eintr\u00e4gen (500 Alarme x 50 Lagerorte).</li> </ul> <p>Insgesamt sind die weiteren Entit\u00e4ten also zu vernachl\u00e4ssigen, da sie nur eine geringe Anzahl an Instanzen haben.  Au\u00dferdem gilt es zu beachten, dass der Gro\u00dfteil der Daten der weiteren Entit\u00e4ten sich in der Regel nicht st\u00e4ndig \u00e4ndern, sondern einmal angelegt werden und ggf. selten aktualisiert werden.</p>"},{"location":"content/arc/data_eva/#datengroe","title":"Datengr\u00f6\u00dfe","text":""},{"location":"content/arc/data_eva/#measurement_1","title":"Measurement:","text":"<p>Die Messwerte sind in der Regel numerisch (z.B. Temperatur, Luftfeuchtigkeit) und ben\u00f6tigen daher wenig Speicherplatz. </p> Datenfeld Typ Gr\u00f6\u00dfe (Bytes) Beschreibung timestamp Datetime 8 Timestamp value Float 4 Numerisch unit String 2 Einheit als Kurzstring (z.B. \"C\") sensor_type String 2-4 Sensortyp storage_id Integer 2 Lagerortreferenz Gesamt - ~18 Durchschnittlich pro Messung <p>Gesamtvolumen: 864.000 Messungen \u00d7 ~ 18 Byte = ~15,5 MB</p>"},{"location":"content/arc/data_eva/#weitere-entitaten_1","title":"Weitere Entit\u00e4ten:","text":"<p>Der Speicherbedarf der weiteren Entit\u00e4ten ist ebenfalls gering, da sie nur wenige Attribute haben und in der Regel nicht sehr viele Instanzen existieren. </p> <ul> <li>Anschaulich l\u00e4sst sich dies am Beispiel der User-Entit\u00e4t darstellen, die folgende Attribute hat:</li> </ul> Datenfeld Typ Gr\u00f6\u00dfe (Bytes) id Integer 4 username String 20 password (hash) String 64 role_id Integer 2 description String 50 storage_id Integer[] 8 Gesamt - ~150 <p>Gesamtvolumen f\u00fcr 500 User: 500 User \u00d7 ~ 150 Byte = ~75 KB</p>"},{"location":"content/arc/data_eva/#nichtfunktionale-anforderungen-datendomane","title":"Nichtfunktionale Anforderungen &lt;=&gt; Datendom\u00e4ne","text":""},{"location":"content/arc/data_eva/#einfluss-der-nicht-funktionalen-anforderungen-auf-die-datendomane","title":"Einfluss der nicht-funktionalen Anforderungen auf die Datendom\u00e4ne","text":"<p>Die definierten nicht-funktionalen Anforderungen beinflussen ggf. direkt die Auswahl der richtigen Datenbanktechnologie und werden dementsprechend im Folgenden auf die Datendom\u00e4ne \u00fcbertragen.</p>"},{"location":"content/arc/data_eva/#performance-und-schnelle-alarmierung","title":"Performance und schnelle Alarmierung","text":"<p>Die Anforderung, einen Alarm innerhalb von 90 Sekunden auszul\u00f6sen, nachdem ein Grenzwert f\u00fcr \u00fcber 30 Sekunden verletzt wurde, stellt eine hohe Anforderung an die Datenbank-Performance. Dies erfordert mehr als nur eine schnelle Einzelabfrage. Die Datenbank muss folgende Operationen sehr effizient unterst\u00fctzen:</p> <ol> <li>Schnelles Schreiben (Ingestion): Jeder neue <code>Measurement</code>-Datensatz muss mit minimaler Latenz gespeichert werden, damit die Alarmierungskette sofort starten kann.</li> <li>Effiziente Zeitfenster-Abfragen: Um eine 30-sek\u00fcndige Grenzwertverletzung zu erkennen, muss das System eine Abfrage wie \"Gib mir alle Messwerte von <code>sensor_x</code> der letzten 30-40 Sekunden\" sehr schnell ausf\u00fchren k\u00f6nnen. Dies verlangt Indexierungsf\u00e4higkeiten, insbesondere auf den Feldern <code>timestamp</code> und <code>sensor_id</code>.</li> </ol>"},{"location":"content/arc/data_eva/#hohe-verfugbarkeit","title":"Hohe Verf\u00fcgbarkeit","text":"<p>Die geforderte Verf\u00fcgbarkeit von 99% \u00fcber einen Zeitraum von drei Tagen erlaubt eine maximale Ausfallzeit von ca. 43 Minuten.</p> <ul> <li>Stabilit\u00e4t und Datenpersistenz: Die Datenbank muss ein robuster, stabiler Dienst sein, der Daten zuverl\u00e4ssig auf die Festplatte schreibt. Bei einem Neustart d\u00fcrfen so keine Daten verloren gehen (was beispielsweise reine In-Memory-Datenbanken ausschlie\u00dft). Basierend auf der Anforderung einer Verf\u00fcgbarkeit von 99% muss die Technologie stabil innerhalb einer Docker-Umgebung laufen.</li> <li>Unterst\u00fctzung f\u00fcr Resilienz: Die Anforderung des automatischen Neustarts wird von der Infrastruktur (Docker Compose) umgesetzt. Die Datenbank muss diesen Prozess jedoch zuverl\u00e4ssig unterst\u00fctzen, d.h. nach einem unerwarteten Herunterfahren schnell und konsistent wieder hochfahren.</li> </ul>"},{"location":"content/arc/data_eva/#sicherheit-authentifizierung-autorisierung","title":"Sicherheit (Authentifizierung &amp; Autorisierung)","text":"<p>Diese Anforderung betrifft prim\u00e4r die Anwendungslogik, aber die Datenbank muss die sichere Implementierung unterst\u00fctzen:</p> <ul> <li>Sichere Datenspeicherung: Die Datenbank muss sensible Daten wie gehashte Passw\u00f6rter in der <code>User</code>-Entit\u00e4t sicher speichern.</li> <li>Unterst\u00fctzung relationaler Integrit\u00e4t: Um die Autorisierung (wer darf auf welchen <code>Storage</code> zugreifen?) sicherzustellen, muss die Datenbank die Beziehungen zwischen <code>User</code>, <code>Role</code> und <code>Storage</code> zuverl\u00e4ssig abbilden k\u00f6nnen. Ein System, das diese Beziehungen durch Constraints und Fremdschl\u00fcssel auf Datenbankebene garantiert, ist hier also wichtig, da es das Risiko von Fehlern in der Anwendungslogik reduziert.</li> </ul>"},{"location":"content/arc/data_eva/#datenbankauswahl-kriterien","title":"Datenbankauswahl - Kriterien","text":"<p>Die Auswahl der Datenbanktechnologie erfolgt nun anhand folgender Kriterien:</p> <ul> <li>Unterst\u00fctzung des Datenmodells: Die Datenbank muss in der Lage sein, die definierten Entit\u00e4ten und deren Beziehungen (vgl. Datenmodellierung) effizient abzubilden. Beispielsweise gilt es die Grundlage f\u00fcr die Sicherheit des Systems zu schaffen (vgl. Nichtfunktionale Anforderungen &lt;=&gt; Datendom\u00e4ne).  </li> <li>Komplexit\u00e4t: Die Implementierung des Datenmodells sollte sich insbesondere den fachlichen Rahmenbedingungen des Projekts anpassen.  Aufgrund der Projektlaufzeit von 2.5 Monaten und der Teamgr\u00f6\u00dfe von 4 Personen gilt es somit unn\u00f6tige Komplexit\u00e4t zu vermeiden. </li> <li> <p>Anmerkung: Das berechnete Datenvolumen ist mit unter 1 MB pro Woche sehr gering. Daher sind Skalierungsmechanismen (wie z.B. horizontales Sharding) f\u00fcr dieses Projekt nicht relevant. Das Kriterium bewertet stattdessen, wie gut die Datenbanktechnologie mit diesem spezifischen, moderaten Datenvolumen umgeht, ohne unn\u00f6tigen administrativen oder ressourcentechnischen Overhead zu erzeugen. </p> </li> <li> <p>Performance: Die Leistungsf\u00e4higkeit der Datenbank ist entscheidend f\u00fcr die Realisierung des schnellen Alarmsystems (vgl. Nichtfunktionale Anforderungen &lt;=&gt; Datendom\u00e4ne). Hierbei gilt es insbesondere die Messdaten, die den Gro\u00dfteil des Datenvolumens ausmachen, effizient zu verwalten.  </p> </li> <li> <p>Betriebsstabilit\u00e4t: Die Datenbank sollte robust im Betrieb sein - entscheidend ist es, einen konsistenten Betrieb mit minimaler Ausfallzeit zu gew\u00e4hrleisten (vgl. Nichtfunktionale Anforderungen &lt;=&gt; Datendom\u00e4ne).  </p> </li> <li>Datenintegrit\u00e4t und Konsistenz: Dieses Kriterium bewertet die F\u00e4higkeit der Datenbank, die Korrektheit und Widerspruchsfreiheit der Daten sicherzustellen. Weiter ist die Garantie wichtig, dass Daten nach dem Speichern nicht verloren gehen oder korrumpiert werden (Datenpersistenz). Dies ist insbesondere f\u00fcr die Verwaltung der Nutzer mit ihren Rechten wichtig.  </li> <li>Abfragem\u00f6glichkeiten f\u00fcr Visualisierung: Die F\u00e4higkeit der Abfragesprache, komplexere Aggregationen (z.B. Durchschnittswerte, Gruppierungen) und Verkn\u00fcpfungen zu formulieren, die f\u00fcr die Erstellung eines Dashboards wichtig sind. Die Kompatibilit\u00e4t mit Standard-Visualisierungstools ist hier ebenfalls relevant.</li> </ul>"},{"location":"content/arc/data_eva/#sql-vs-nosql","title":"SQL vs NoSQL","text":"<p>Die folgende Tabelle evaluiert einen relationalen SQL-Ansatz und einen dokumentenorientierten NoSQL-Ansatz anhand der festgelegten Kriterien:</p> <p>Anmerkung: F\u00fcr den Vergleich wird als NoSQL-Typ die dokumentorientierte Datenbank initial ausgew\u00e4hlt, da jeder Measurement-Datensatz eine in sich geschlossene Informationseinheit darstellt (Zeitstempel, Wert, Sensor-ID etc.), die sich nativ als ein JSON-\u00e4hnliches Dokument abbilden l\u00e4sst. Dieser Ansatz ist als einziger NoSQL-Typ flexibel genug, um sowohl die zeitreihenbasierten Measurement-Daten als auch die eher strukturierten Entit\u00e4ten wie User und Storage in separaten Collections zu verwalten.</p> Kriterium SQL-Ansatz (Relational) NoSQL-Ansatz (Dokumentenorientiert) Unterst\u00fctzung des Datenmodells Sehr gut. Das relationale Modell eignet sich sehr gut, um die strukturierten Beziehungen zwischen User, Role und Storage durch Foreign Keys abzubilden. Die Measurement-Daten passen in eine separate, nach Zeitstempel indizierte Tabelle. Okay. Sehr gut f\u00fcr die flexiblen Measurement-Daten. Die Abbildung der relationalen Benutzer- und Zugriffsdaten ist jedoch umst\u00e4ndlich. Beziehungen m\u00fcssen in der Anwendungslogik (\u00fcber Referenzen oder eingebettete Dokumente) verwaltet werden, was die Komplexit\u00e4t erh\u00f6ht. Komplexit\u00e4t Gering. Das Datenmodell l\u00e4sst sich intuitiv auf Tabellen abbilden. Die Datenbank \u00fcbernimmt die Logik der Beziehungsintegrit\u00e4t. Das moderate Datenvolumen erfordert keinen administrativen Mehraufwand. Mittel. W\u00e4hrend das Speichern der IoT-Daten einfach ist, erfordert die konsistente Abbildung der Benutzer-Zugriffsrechte mehr Entwicklungsaufwand. Der gr\u00f6\u00dfte Vorteil \u2013 die einfache Skalierung bei riesigen Datenmengen \u2013 ist hier nicht relevant und f\u00fchrt zu unn\u00f6tigem konzeptionellen Overhead. Performance Sehr gut. Moderne SQL-Datenbanken k\u00f6nnen das moderate Datenvolumen m\u00fchelos verarbeiten. Schnelle Schreibvorg\u00e4nge und effiziente Zeitfenster-Abfragen f\u00fcr die Alarmierung sind durch Standard-Indizes auf den Zeitstempel- und Sensor-Feldern ohne Probleme und performant realisierbar. Sehr gut. Hohe Schreibleistung ist eine Kernst\u00e4rke der meisten NoSQL Datenbanken. Die Abfragegeschwindigkeit f\u00fcr die Alarmierung w\u00e4re ebenfalls sehr gut. Bei diesem Anwendungsfall mit der geringen Datenmenge ist ein Performancevorteil jedoch fraglich. Betriebsstabilit\u00e4t Sehr hoch. Etablierte SQL-Datenbanken wie PostgreSQL sind f\u00fcr ihre Robustheit und stabilen Betrieb bekannt. Sie unterst\u00fctzen einen zuverl\u00e4ssigen Neustart nach Ausf\u00e4llen und f\u00fcgen sich nahtlos in Docker-Umgebungen ein. Sehr hoch. Moderne NoSQL-Datenbanken sind ebenfalls f\u00fcr den stabilen Dauerbetrieb ausgelegt und f\u00fcr ihre Resilienz in verteilten Systemen bekannt. Datenintegrit\u00e4t &amp; Konsistenz Sehr hoch (nativ). Durch ACID-Transaktionen und Constraints (UNIQUE, FOREIGN KEY) wird die Konsistenz der Daten auf Datenbankebene erzwungen. Dies ist besonders f\u00fcr die Verwaltung von Benutzerrechten und die Sicherheit des Systems ein entscheidender Vorteil. Mittel. Bietet standardm\u00e4\u00dfig schw\u00e4chere Konsistenzmodelle (Eventual Consistency). Obwohl moderne Systeme auch ACID-Transaktionen unterst\u00fctzen, liegt die Verantwortung f\u00fcr die Datenintegrit\u00e4t bei relationalen Verkn\u00fcpfungen gr\u00f6\u00dftenteils beim Entwickler im Anwendungscode. Abfragem\u00f6glichkeiten f\u00fcr Visualisierung Sehr gut. Die standardisierte Abfragesprache SQL ist geeignet f\u00fcr komplexe Aggregationen (GROUP BY) und Verkn\u00fcpfungen (JOIN), die f\u00fcr Dashboards wichtig sind (z.B. Anzeige von Lagerortnamen zu Messwerten). Gut. Propriet\u00e4re Abfragesprachen sind m\u00e4chtig, aber weniger standardisiert. Das Verkn\u00fcpfen von Daten aus unterschiedlichen Collections ist oft aufwendiger als ein SQL-JOIN. <p>Der Vergleich zeigt, dass der SQL-Ansatz f\u00fcr das Projekt die bessere Wahl ist. Die St\u00e4rken des relationalen Modells in Bezug auf Datenintegrit\u00e4t, Konsistenz und die einfache Abbildung der Beziehungen zwischen den Entit\u00e4ten sind entscheidend. Insgesamt l\u00e4sst sich das Datenmodell so leichter (und schneller) umsetzen. Performance und Betriebsstabilit\u00e4t sind in beiden F\u00e4llen hoch, aber der SQL-Ansatz bietet eine klarere Struktur f\u00fcr die Verwaltung der Benutzerrechte und Zugriffe.  Weiter l\u00e4sst sich die Performance, insbesondere hinsichtlich der Measurement-Daten, in der SQL-Datenbank durch Indizes auf beispielsweise den Zeitstempel manuell beziehungsweise durch Nutzung einer spezialisierten SQL-Datenbank (Timeseries) verbessern.  Auch die Abfragem\u00f6glichkeiten im Zuge der Visualisierung mittels eines Dashboards sind im SQL-Ansatz gegeben, da SQL eine standardisierte und m\u00e4chtige Abfragesprache bietet, die komplexe Aggregationen und Verkn\u00fcpfungen unterst\u00fctzt. </p>"},{"location":"content/arc/data_eva/#datenbanktechnologie-postgresql-mit-timescaledb","title":"Datenbanktechnologie - PostgreSQl mit TimescaleDB","text":"<p>Um einerseits die einfachen, zeitabh\u00e4ngigen Messreihen effizient verwalten zu k\u00f6nnen und andererseits die \"relationalen Metadaten\" (User, Role, Storage) mit ihren Beziehungen abzubilden, wird die PostgreSQL-Datenbank ausgew\u00e4hlt.  Diese hat sich als eine der leistungsf\u00e4higsten Open-Source-Datenbanken etabliert und bietet neben dem klassichen relationalen Ansatz auch Unterst\u00fctzung f\u00fcr zeitbasierte Daten durch die Erweiterung TimescaleDB.  TimescaleDB ist eine Erweiterung f\u00fcr PostgreSQL, die speziell f\u00fcr die Speicherung und Abfrage von Zeitreihendaten entwickelt wurde. Sie bietet Funktionen wie automatische Partitionierung (Chunking) und Indizierung, die die Performance bei zeitbasierten Abfragen erheblich verbessern [1].  F\u00fcr das Projekt bietet diese Kombination folgende Vorteile, die direkt auf die zuvor definierten Auswahlkriterien abzielen:</p> <ul> <li>Optimale Performance f\u00fcr die Alarmierung: Die zentrale Anforderung des schnellen Alarmsystems wird durch TimescaleDB ideal unterst\u00fctzt. Die Measurement-Tabelle wird als sogenannte Hypertable konfiguriert. Dadurch werden die Messdaten im Hintergrund automatisch nach Zeit partitioniert, was Abfragen auf kurzen Zeitfenstern (\"alle Werte der letzten 30 Sekunden\") extrem performant macht.</li> <li>Hohe Datenintegrit\u00e4t bei geringer Komplexit\u00e4t: W\u00e4hrend TimescaleDB die Zeitreihendaten optimiert, k\u00fcmmert sich der PostgreSQL-Kern um die relationalen Daten. Die Beziehungen zwischen User, Role und Storage werden durch Foreign Keys und ACID-Transaktionen auf Datenbankebene abgesichert. Dies erm\u00f6glicht die Datenkonsistenz, reduziert den Entwicklungsaufwand im Backend und vermeidet Komplexit\u00e4t.</li> <li>Python-Entwickler-Unterst\u00fctzung: PostgreSQL ist im Python-\u00d6kosystem integriert und wird von Bibliotheken wie SQLAlchemy optimal unterst\u00fctzt. Die Verwendung von standardisiertem SQL erleichtert zudem die Anbindung von Visualisierungs-Tools und die Formulierung komplexer Abfragen f\u00fcr das Analyse-Dashboard.</li> <li>Betriebsstabilit\u00e4t: Obwohl das aktuelle Datenvolumen gering ist, ist das System von Anfang an f\u00fcr ein potenzielles Wachstum der Sensordaten ausgelegt. Die Betriebsstabilit\u00e4t von PostgreSQL erm\u00f6glicht zudem die geforderte hohe Verf\u00fcgbarkeit in einer Docker-Umgebung [2].</li> <li>Open-Source: PostgreSQL ist eine weit verbreitete Open-Source-Datenbank mit einer gro\u00dfen Community. Langfristige Unterst\u00fctzung, regelm\u00e4\u00dfige Updates und eine Vielzahl von Ressourcen und Features f\u00fcr Entwickler werden so kostenlos erm\u00f6glicht.</li> </ul>"},{"location":"content/arc/data_eva/#timescaledb-unter-der-haube-1","title":"TimescaleDB unter der Haube [1]","text":"<p>Die TimescaleDB-Erweiterung steigert die Effizienz bei der Verarbeitung von zeitabh\u00e4ngigen Messreihen in PostgreSQL durch einen optimierten Mechanismus: Die automatische Partitionierung von Daten in sogenannte Hypertables.</p> <p>Grunds\u00e4tzlich gilt: Je l\u00e4nger die Laufzeit des Systems, desto mehr Messwerte werden erfasst und desto mehr lassen sich die Vorteile von TimescaleDB erkennen.</p>"},{"location":"content/arc/data_eva/#1-hypertables-chunks","title":"1. Hypertables, Chunks:","text":"<ul> <li>Anstatt alle Messwerte in einer einzigen, riesigen Tabelle zu speichern, wandelt TimescaleDB die Tabelle in eine sogenannte Hypertable um.    Diese Hypertable ist eine virtuelle Abstraktion, die im Hintergrund aus vielen kleineren, physischen Tabellen (= Chunks) besteht.</li> <li>Automatische Partitionierung: TimescaleDB teilt die Daten automatisch nach einem Zeitintervall in diese Chunks auf.    Beispielweise kann festlegt werden, dass f\u00fcr jede Woche ein neuer Chunk erstellt wird.    Alle Messwerte, die in dieser Woche anfallen, werden ausschlie\u00dflich in diesen einen Chunk geschrieben.</li> </ul>"},{"location":"content/arc/data_eva/#2-mogliche-effizienzgewinne","title":"2. (M\u00f6gliche) Effizienzgewinne:","text":"<ul> <li>Schnellere Abfragen (Query Performance): Wenn man eine Abfrage startet, die auf einen kurzen Zeitraum begrenzt ist (z.B. \"Gib mir alle Temperaturwerte der letzten Minute\"), muss PostgreSQL nicht die gesamte Tabelle durchsuchen. Stattdessen identifiziert TimescaleDB sofort, welcher Chunk (oder welche wenigen Chunks) die Daten f\u00fcr diesen Zeitraum enth\u00e4lt, und scannt nur diese sehr kleinen Tabellen.</li> <li>Schnelleres Schreiben (Ingest Performance):    Neue Messwerte werden immer nur in den neuesten Chunk geschrieben. Da dieser Chunk relativ klein ist und oft vollst\u00e4ndig im Arbeitsspeicher gehalten wird, bleibt der Schreibvorgang konstant schnell, selbst wenn das Gesamtvolumen der historischen Daten auf ssehr viele Eintr\u00e4ge (z.B. Millionen) anw\u00e4chst.    Ohne TimescaleDB w\u00fcrden die Indizes einer einzigen gro\u00dfen Tabelle mit der Zeit fragmentieren und Schreibvorg\u00e4nge verlangsamen.</li> <li>Datenverwaltung:<ul> <li>L\u00f6schen: Das L\u00f6schen alter Daten (z.B. \"alle Messwerte \u00e4lter als ein Jahr\") wird effizienter, da durch die Chunks ganze Tabellen auf einmal mit (DROP TABLE) entfernt werden k\u00f6nnen, anstatt Zeile f\u00fcr Zeile zu l\u00f6schen.</li> <li>Komprimierung - Speicherbedarf: TimescaleDB bietet auch eine eingebaute Komprimierung f\u00fcr \u00e4ltere Chunks, die den Speicherbedarf weiter reduziert.</li> <li>Komprimierung - Abfragegeschwindigkeit: TimescaleDB kann auf die Daten im komprimierten Zustand wie in einem spaltenorientierten Format zugreifen. Anstatt eine ganze Zeile mit allen Datenfeldern (timestamp, value, unit etc.) lesen zu m\u00fcssen (wie es bei klassicher seitenweiser Speicherung der Fall ist), kann die Datenbank gezielt nur die Spalten abrufen, die f\u00fcr die Abfrage ben\u00f6tigt werden \u2013 zum Beispiel nur den value.</li> </ul> </li> </ul>"},{"location":"content/arc/data_eva/#datenbank","title":"Datenbank","text":"<p>Die modellierte Datenbank sieht wie folgt aus:</p> <p></p> <p>Hierbei wurden die folgenden Konzepte wahrgenommen:</p> <ul> <li>Jeder Nutzer hat Zugriff auf mehrere Lagerorte und jeder Lagerort kann von mehreren Nutzern zugegriffen werden.   Aus diesem Grund gibt es eine many-to-many Beziehung zwischen Nutzern und Lagerorten, bzw. zwischen der <code>User</code>   und der <code>Storage</code> Tabelle. Der Zugriff auf ein Lagerort erfolgt durch den eindeutigen Namen des Lagerorts und   des dazugeh\u00f6rigen Passworts.</li> <li>Unterschiedliche Nutzer sollen adequate Rechte auf diesen haben k\u00f6nnen. Beispielsweise soll es Administratoren   und gew\u00f6hnliche Nutze geben. Daher existiert ein Feld <code>user_role</code> vom Typ <code>UserRole</code> in der Tabelle   <code>UserStorageAccess</code>. Dieser Datentyp ist lediglich ein ENUM.</li> <li>Ein Lagerort soll mehrere Sensore haben, daher die many-to-one Beziehung zwischen den Tabellen <code>Sensor</code> und   <code>Storage</code>. Zus\u00e4tzlich hat ein Sensor Grenzwerte, zwischen denen Messungen liegen sollten, um Sch\u00e4den in den   Waren zu vermeiden, daher die Felder <code>allowed_min</code> und <code>allowed_max</code>.</li> <li>Jeder Sensor nimmt daten auf. Daher wurde eine Tabelle <code>Measurement</code> eingef\u00fchrt, die eine many-to-one Beziehung   zur Tabelle <code>Sensor</code> hat. Das Feld <code>unit</code> ist vom ENUM Typ <code>MeasurementUnit</code>, welches alle m\u00f6glichen Einheiten   beinhaltet (z.B. <code>CELSIUS</code> und <code>FAHRENHEIT</code> f\u00fcr die Temperatur, <code>PERCENT</code> f\u00fcr die Luftfeuchtigkeit usw.). Dieser   Datentyp soll inkonsistenzen vermeiden, die es bei gew\u00f6hnlichem Text gibt (z.B. beziehen sich <code>Celsius</code> und <code>C</code>   auf die selbe Einheit). Das Feld <code>created_at</code> bezoeht sich auf den genauen Zeitpunkt der Messung der Daten.   Diese Tabelle soll eine Hypertable sein, um die Messungen m\u00f6glichst effizient abrufen zu k\u00f6nnen.</li> <li>Messungen, die die Grenzwerte des Sensors \u00fcberschreiten, l\u00f6sen ein Alarm aus, daher die Tabelle <code>Alarm</code>.   das Feld <code>severity</code> vom ENUM Typ <code>AlarmSeverity</code> beschreibt die Schwere des Alarms (<code>HIGH</code>, <code>MEDIUM</code>, <code>LOW</code>).   Das Feld <code>message</code> ist eine vom System generierte Nachricht, die den Alarm beschreibt und dem Nutzer angezeigt wird.</li> </ul> <p>Quellen:</p> <ul> <li>[1] PostgreSQL + TimescaleDB: 1,000x Faster Queries, 90 % Data Compression, and Much More</li> <li>[2] Install TimescaleDB from a Docker container</li> <li>Storing IoT Data: 8 Reasons Why You Should Use PostgreSQL</li> <li>The benefits of PostgreSQL</li> <li>PostgreSQL: a closer look at the object-relational database management system</li> </ul>"},{"location":"content/arc/components/arduino/","title":"Arduino Codebase","text":""},{"location":"content/arc/components/arduino/#struktur","title":"Struktur","text":"<p>Die Codebase f\u00fcr das Arduino System ist so aufgebaut, dass eine einfache Einf\u00fchrung von weiteren Sensoren m\u00f6glich ist. Um dies zu erreichen wurde eine Klasse <code>AbstractSensor</code> angelegt, die allgemeine Eigenschaften und Funktionalit\u00e4ten eines Sensors besitzt. Diese sind folgende:</p> <ul> <li>Jeder Sensor hat einen Namen. Dieser wird einmalig im Konstruktor festgelegt und kann mit der Methode   <code>AbstractSensor::getName</code> gelesen werden. Der Name des Sensors ist lediglich aus Logging-Gr\u00fcnden hilfreich.</li> <li>Eine Methode <code>AbstractSensor::setup</code> soll einmalig in der <code>setup</code> Funktion des Arduino Sketch aufgerufen werden.   In dieser Methode k\u00f6nnen beispielsweise die Sensore konfiguriert werden. Diese Methode ist abstrakt und muss in   geeigneten Unterklassen \u00fcberschrieben werden.</li> <li>Jeder sensor kann Daten als <code>float</code> auslesen. Dies wird durch die Methode <code>AbstractSensor::readData</code> erreicht.   Diese Methode ist ebenfalls abstrakt und muss in geeigneten Unterklassen \u00fcberschrieben werden.</li> <li>Zus\u00e4tzlich gibt es eine Methode, um ausgelesene Daten an den MQTT Broker zu senden. Dies wird durch die Methode   <code>AbstractSensor::publishData</code> erreicht; hierbei werden als Parameter der MQTT Client und das MQTT Topic \u00fcbergeben   und eine Nachricht wird damit automatisch an den Broker gesendet. Hier wird die Methode <code>AbstractSensor::readData</code>   verwendet, um die gemessenen Daten auszulesen.</li> </ul>"},{"location":"content/arc/components/arduino/#watchdog-integration","title":"Watchdog-Integration","text":"<p>Zur Absicherung des Systems gegen dauerhafte Verbindungsprobleme wurde ein Software-Watchdog implementiert. Dieser stellt sicher, dass das System in einem definierten Zeitraum automatisch neu startet, wenn eine Wiederverbindung zum MQTT-Broker nicht gelingt. Diese Funktionalit\u00e4t ist besonders wichtig f\u00fcr produktive Anwendungen mit dauerhafter Daten\u00fcbertragung, wie im MVP vorgesehen.</p>"},{"location":"content/arc/components/arduino/#anforderungen","title":"Anforderungen","text":"<p>Im MVP war festgelegt, dass das Ger\u00e4t sich nach einem Verbindungsverlust innerhalb von 30 Sekunden wieder mit dem MQTT-Broker verbinden soll. Gelingt dies nicht innerhalb von 3 Versuchen, muss ein automatischer Neustart erfolgen \u2013 idealerweise innerhalb von 20 Sekunden nach letztem Versuch. Diese Anforderungen wurden durch folgende Mechanismen erf\u00fcllt:</p> <ul> <li>Reconnect-Logik mit Z\u00e4hler und 30 s-Zeitfenster</li> <li>In-Sketch Watchdog, umgesetzt \u00fcber <code>millis()</code>-Timing und Neustart via <code>NVIC_SystemReset()</code></li> </ul>"},{"location":"content/arc/components/arduino/#vergleich-alternativer-watchdog-bibliotheken","title":"Vergleich alternativer Watchdog-Bibliotheken","text":"<p>F\u00fcr SAMD21-kompatible Boards existieren mehrere Watchdog-Bibliotheken:</p> Bibliothek Hardwarebasiert Einfachheit Max. Timeout Verbreitung <code>WDTZero</code> Ja Hoch 8 s H\u00e4ufig <code>Sodaq_wdt</code> Ja Mittel 8 s \ufe0f Weniger verbreitet <code>WDT_SAMD21</code> Ja Mittel 16 s \ufe0f Selten <code>In-Software-Watchdog</code> Nein Hoch \ufe0f frei w\u00e4hlbar H\u00e4ufig <p>Die Entscheidung fiel auf In-Sketch Watchdog, da sie:</p> <ul> <li>freie Wahl der Timeout-Dauer (z. B. 20 s) erm\u00f6glicht</li> <li>keine zus\u00e4tzliche Bibliothek ben\u00f6tigt</li> <li>pr\u00e4zise im Sketch \u00fcber <code>millis()</code> und <code>NVIC_SystemReset()</code> arbeitet</li> </ul>"},{"location":"content/arc/components/arduino/#implementierung","title":"Implementierung","text":"<p>Die Watchdog-Funktionalit\u00e4t wird direkt im Sketch umgesetzt, ganz ohne externe Bibliothek. Wir verwenden einen millis()-basierten Timer und rufen <code>NVIC_SystemReset()</code> auf, wenn seit dem letzten erfolgreichen Poll/Connect mehr als 20\u00a0s vergangen sind.</p> <ol> <li> <p>Parameter und State</p> <p>Hier definieren wir die Anzahl der Maximalversuche sowie die Zeitfenster f\u00fcr Reconnect und Reset.    ```cpp    const int    MAX_ATTEMPTS         = 3;      // max. Reconnect-Versuche    const long   RECONNECT_WINDOW_MS  = 30000;  // 30 s-Fenster    const long   RESTART_TIMEOUT_MS   = 20000;  // 20 s bis Reset</p> </li> </ol> <p>int          attempts     = 0;    unsigned long windowStart = 0;    unsigned long lastConnect = 0;  // Zeitstempel letzten Connects     ```</p> <ol> <li> <p>Reconnect-Logik und Software-Reset im loop()</p> <p>Im Hauptloop wird zun\u00e4chst gepr\u00fcft, ob die MQTT-Verbindung aktiv ist. Ist dies der Fall, wird der MQTT-Client gepollt, ein Temperatursensor ausgelesen und der letzte erfolgreiche Connect-Zeitpunkt gespeichert. <pre><code>void loop() {\n  unsigned long now = millis();\n\n  if (mqttClient.connected()) {\n    mqttClient.poll();\n    lastConnect = now;\n\n    float temperature = tempSensor-&gt;readData();\n    Serial.print(\"Temperature: \");\n    Serial.print(temperature);\n    Serial.println(\"\u00b0C\\n---\");\n    tempSensor-&gt;publishData(mqttClient, MQTT_TOPIC_TEMPERATURE);\n    delay(5000);\n</code></pre> Ist die Verbindung nicht aktiv, beginnt die Fehlerbehandlung. Zuerst wird gepr\u00fcft, ob das aktuelle Reconnect-Fenster abgelaufen ist \u2013 falls ja, wird der Z\u00e4hler zur\u00fcckgesetzt: <pre><code>} else {\nif (now - windowStart &gt; RECONNECT_WINDOW_MS) {\n  windowStart = now;\n  attempts = 0;\n  Serial.println(\"Neues 30s-Fenster \u2013 Versuchsz\u00e4hler zur\u00fcckgesetzt\");\n}\n</code></pre></p> <p>Dann wird gepr\u00fcft, ob der Broker \u00fcber TCP erreichbar ist. Dies hilft dabei zu unterscheiden, ob der Fehler im VPN oder beim MQTT-Connect liegt: <code>cpp if (!isBrokerReachable()) {    attempts++;    Serial.print(\"Broker unreachable, Versuch \");    Serial.print(attempts);    Serial.println(\"/3\");  } else {</code></p> <p>Ist der Broker erreichbar, aber MQTT noch nicht verbunden, wird ein Verbindungsversuch unternommen: <pre><code>if (tryConnectMQTT()) {\n    Serial.println(\"MQTT verbunden, ready to publish.\");\n    attempts = 0;\n    lastConnect = now;\n  } else {\n    attempts++;\n    Serial.print(\"MQTT connect fail, Versuch \");\n    Serial.print(attempts);\n    Serial.println(\"/3\");\n    delay(1000);\n  }\n}\n</code></pre> Schlie\u00dflich wird \u00fcberwacht, ob seit dem letzten erfolgreichen Connect mehr als 20 Sekunden vergangen sind. Wenn ja, erfolgt ein Neustart des Systems \u00fcber NVIC_SystemReset(): <pre><code>if (lastConnect != 0 &amp;&amp; now - lastConnect &gt; RESTART_TIMEOUT_MS) {\n  Serial.println(\"Timeout \u2013 Neustart\");\n  delay(100);\n  NVIC_SystemReset();\n}\n</code></pre></p> </li> </ol>"},{"location":"content/arc/components/arduino/#quellen","title":"Quellen","text":"<ul> <li>[1] WDTZero GitHub</li> <li>[2] Sodaq_Watchdog Github</li> <li>[3] WDT_SAMD21 GitHub (Alternative)</li> <li>[4] Arduino millis()-documentation</li> <li>[5] Long time use of millis</li> <li>[6] MQTT-Reconnect-Logik mit ArduinoMqttClient</li> <li>[7] NVIC_SystemReset() documentation</li> </ul>"},{"location":"content/arc/components/backend/","title":"MQTT Client","text":""},{"location":"content/arc/components/backend/#funktionalitat","title":"Funktionalit\u00e4t","text":"<p>Aus der in der Architektur</p>"},{"location":"content/arc/components/mqtt-client/","title":"MQTT Client","text":""},{"location":"content/arc/components/mqtt-client/#fuktionalitat","title":"Fuktionalit\u00e4t","text":"<p>Aus der Architektur und dem MVP k\u00f6nnnen folgende nicht funktionale Anforderungen an den MQTT Client abgeleitet werden. - Resillienz gegen Fehler: Der Client sollte sowohl den Ausfall des Brokers sowie den des Backends abfangen, und sich selbsts\u00e4ndig wieder verbinden k\u00f6mnen. - Verhinderung von Datenverlust: Der Client sollte bei Ausfall des Backends die Nachrichten des Brokers zwischenspeichern(cashen).</p>"},{"location":"content/arc/components/mqtt-client/#architektur","title":"Architektur","text":"<p>Um das Cashing zu realisieren, m\u00fcssen die Nachrichten des Brokers zwischengespeichert werden. Dies wird durch eine SQL Datenbank realisiert. Diese Datenbankarchitektur wurde aufgrund der zu erwartenden geringen Datenmenge gew\u00e4hlt. Des Weiteren ist die Persistenz der Nachrichten bei einer SQL Datenbank ohne weitere Konfiguration gegeben. Um gecashte Nachrichten auch versenden zu k\u00f6nnen, wenn keine neuen Nachrichten vom Broker empfangen werden,wird das versenden in einen eigenen Thread ausgelagert. Dies wurde einer eigenst\u00e4ndigem Service vorgezogen, um die Komplexit\u00e4t des Dockerfiles zu reduzieren. Der Ablauf einer Nachricht wird in folgender Abbildung dargestellt: </p>"},{"location":"content/arc/components/mqtt-client/#umsetzung","title":"Umsetzung","text":"<p>Der  Client wird nach dem in der Architektur beschriebenen Konzept in Python umgesetzt. F\u00fcr den MQTT Connector wird die Bibliothek <code>paho-mqtt</code> verwendet, da diese einen weiten Verbreitungsgrad hst und alle n\u00f6tigen Funktionalit\u00e4ten bietet. Die Bufferdatenbank wird mithilfe einer Sqlite Datenbank realisiert. Diese wurde gew\u00e4hlt, da die zu erwartende Datenmenge \u00e4usserst gering ist, und die Datenbank einfach zu konfigurieren ist. Das Senden der Nachrichten wird mithilfe der request Bibliothek umgesetzt. Alle drei Komponenten sind in eigenen Dokumenten umgesetzt. Da das Backend auf einem vom Internet erreichbaren Server l\u00e4uft und dieser nicht auf dem gleichen Server wie der Broker l\u00e4uft, ist der Mqtt Client in einem eigenen Docker Compose umgesetzt.</p>"},{"location":"content/arc/components/alarm/alarm-feat/","title":"Alarm-Feature mit Apache Kafka","text":"<p>Kafka (Broker, KRaft-Modus) * Zentrale Event-/Daten-Drehscheibe f\u00fcr Streams. * Speichert Nachrichten in Topics (z.B. iot-sensordata, alarme). * Erm\u00f6glicht horizontale Skalierung \u00fcber Partitionen. * Garantiert Reihenfolge pro Partition und Consumer-Group-Offsets.</p> <p>Kafka Connect (Laufzeit f\u00fcr Connectoren) * Standardisierte Integrations-Laufzeit, um externe Systeme anzubinden. * F\u00fchrt den MQTT Source Connector aus (und optional einen MQTT Sink). * Verwaltet Connector-Tasks, Status, Offsets und Wiederanl\u00e4ufe. * Deklarative Konfiguration (per JSON/REST)</p> <p>MQTT Source Connector (innerhalb von Connect) * Intialisiert und konfiguriert via INIT-Container (one-shot). * Verbindet sich als MQTT-Client an deinen externen Mosquitto-Broker. * Abonniert MQTT-Topics (z.B. sensor/+) und schreibt Nachrichten in Kafka (iot-sensordata). * Setzt idealerweise die Sensor-ID als Kafka-Key (SMTs), damit pro Sensor deterministisch partitioniert wird. * Erm\u00f6glicht saubere Entkopplung zwischen MQTT-Welt und Kafka.</p> <p>MQTT Sink Connector (innerhalb von Connect) * Konsumiert aus Kafka (z.B. alarme) und publiziert daraus abgeleitete Befehle/Events zur\u00fcck in MQTT. * Erm\u00f6glicht einen R\u00fcckkanal an Ger\u00e4te/Aktoren (z.B. devices/${key}/commands). * Ebenfalls deklarativ konfigurierbar und skalierbar.</p> <p>Kafka-Init (One\u2011Shot Init-Container) * Wartet automatisch, bis Kafka erreichbar ist. * Legt die ben\u00f6tigten Topics idempotent an (iot-sensordata, alarme) mit gew\u00fcnschter Partitionierung. * Beendet sich nach erfolgreicher Initialisierung (keine dauerhafte Last).</p> <p>Kafka UI (Redpanda Console) * Web-Oberfl\u00e4che zur Einsicht in Cluster, Topics, Partitionen, Nachrichten und Consumer-Lags. * Hilfreich f\u00fcr Debugging, Monitoring und manuelle Checks. * \u00dcber Traefik nach au\u00dfen erreichbar.</p> <p>Alarmservice (Kafka Streams) * Konsumiert iot-sensordata keyed by sensor_id. * F\u00fchrt Schwellwertlogik pro individueller Sensor-Messwertaufzeichnung aus. * Produziert strukturierte Alarme (Json) in das Topic alarme. * L\u00e4sst sich horizontal skalieren entsprechend der Partitionen.</p>"},{"location":"content/arc/components/alarm/alarm/","title":"STORASENSE \u2013 Alarmkonzept","text":""},{"location":"content/arc/components/alarm/alarm/#zielbild","title":"Zielbild","text":"<ul> <li>Alarm, wenn Sensorwert au\u00dferhalb <code>[min_value, max_value]</code> liegt und dies \u2265 dwell_time (vom User konfigurierbar) anh\u00e4lt.</li> <li>Kein Flapping: Hysterese + Cooldown, eine aktive Alarm-Instanz pro (user, storage, sensor, rule).</li> <li>Skalierbar auf ~50 Nutzer (\u2248 bis ~500 Sensoren realistisch), zustandsbasiert und streaming-nah (Pr\u00fcfung beim Ingest statt teurer DB-Scans).</li> <li>Push zu FE + Integrationen via WebSocket/SSE und MQTT.</li> </ul>"},{"location":"content/arc/components/alarm/alarm/#1-nicht-funktionale-anforderungen","title":"1) Nicht-funktionale Anforderungen","text":"<ul> <li>Skalierung / Parallelit\u00e4t: Ziel bis 100 Sensoren (Annahme: \u00d8 20 Sensoren/User). \u00d8 1 Messung/Sensor/s \u21d2 bis 100 msg/s Spitze.</li> <li>Latenz: Alarm-Erkennung &lt; 2 s nach Erreichen der dwell_time (bei kontinuierlichem Ingest).</li> <li>Verf\u00fcgbarkeit &amp; Robustheit: Alarm-State wird in DB persistiert, aber im Speicher (Redis/in-proc) gespiegelt; Crash-sicher dank Perioden-Flush.</li> <li>Kosten / Effizienz: Kein Polling gro\u00dfer Zeitr\u00e4ume; In-Memory-State + Event-getriebene Updates (Ingest-Pfad, LISTEN/NOTIFY bei Regel\u00e4nderung).</li> </ul>"},{"location":"content/arc/components/alarm/alarm/#parallel-alarm-policy-pro-nutzer","title":"Parallel-Alarm-Policy (pro Nutzer)","text":"<ul> <li>Soft-Limit: 20 gleichzeitige aktive Sensor-Alarme pro User. Ab Erreichen \u2192 Konsolidierung zu Storage-\u201eStorm\u201c-Alarmen (Z\u00e4hler + Top-Sensoren) und visuelle Warnung im UI.</li> <li>Hard-Limit: 50. Dar\u00fcber hinaus keine neuen Einzel-Alarm-Instanzen; bestehende \u201eStorm\u201c-Alarme werden aktualisiert.</li> <li>Ziel: Alert Fatigue vermeiden, UI &amp; Benachrichtigungen stabil halten, trotzdem Impact sichtbar machen.</li> </ul>"},{"location":"content/arc/components/alarm/alarm/#2-datenmodell","title":"2) Datenmodell","text":"Tabelle Wichtigste Felder Zweck / Beschreibung <code>Sensor</code> min_value, max_value, dwell_seconds, enabled Schwellwerte &amp; Mindestdauer je Sensor <code>Alarm</code> user_id, storage_id, sensor_id, status(PENDING/FIRING/RESOLVED), pending_since, fired_at, resolved_at, last_value, last_ts Aktueller/letzter Alarmzustand je Sensor <code>AlarmEvent</code> (neu) alarm_id (FK \u2192 Alarm.id), ts, state_change(PENDING/FIRING/RESOLVED/ACKED), value, meta(JSONB) Verlauf/Audit der Zustandswechsel <p>Beziehungen: - <code>Alarm.sensor_id \u2192 Sensor.id</code>, <code>Alarm.storage_id \u2192 Storage.id</code>, <code>Alarm.user_id \u2192 User.id</code> - <code>AlarmEvent.alarm_id \u2192 Alarm.id</code> - Zugriff auf Storages steuert ihr wie bisher \u00fcber <code>UserStorageAccess</code>.</p>"},{"location":"content/arc/components/alarm/alarm/#indizes","title":"Indizes","text":"<ul> <li><code>Measurements (sensor_id, timestamp DESC)</code> \u2014 schnelle Zeitreihenabfragen</li> <li><code>Alarm (user_id, status)</code> und <code>Alarm (sensor_id, status)</code> \u2014 aktive Alarme filtern</li> <li><code>AlarmEvent (alarm_id, ts DESC)</code> \u2014 Verlauf pro Alarm effizient anzeigen</li> </ul>"},{"location":"content/arc/components/alarm/alarm/#3-regellogik-zustandsautomat","title":"3) Regellogik &amp; Zustandsautomat","text":"<p>State Machine pro (sensor_id, rule_id): - OK \u2192 PENDING: Wert au\u00dferhalb <code>[min,max]</code> \u21d2 <code>pending_since</code> setzen (falls leer). - PENDING \u2192 FIRING: <code>now \u2212 pending_since \u2265 dwell_seconds</code> \u21d2 <code>fired_at = now</code>, Alarm erzeugen/\u00f6ffnen (falls nicht offen). - FIRING \u2192 RESOLVED: Wert innerhalb erweiterter Hysterese <code>[min+hyst_min, max\u2212hyst_max]</code> f\u00fcr dwell_seconds \u21d2 Alarm schlie\u00dfen (<code>resolved_at</code>), cooldown starten. - Cooldown: innerhalb <code>cooldown_seconds</code> kein Re-Trigger (Debounce). - Silences/Maintenance: aktiv \u21d2 kein Trigger, State l\u00e4uft intern weiter (Diagnose).</p> <p>Zusatz-Regeln (optional, einfach aktivierbar): No-Data (&gt; X min), Rate-of-Change (\u0394Wert/\u0394t), Stuck-Sensor (Varianz ~0 \u00fcber Y min), Gruppen-/Storage-Regel (ANY/ALL \u00fcber Sensorgruppe).</p>"},{"location":"content/arc/components/alarm/alarm/#4-trigger-pfade","title":"4) Trigger-Pfade","text":"<p>Prim\u00e4r (Ingest-Pfad, pro Messung): 1. Rule-Cache (sensor_id \u2192 rule) aus Redis/in-proc, TTL ~60 s; Invalidation via Postgres LISTEN/NOTIFY auf <code>rule_changes</code>. 2. State-Lookup im Cache (<code>sensor_id:rule_id</code>) \u2192 State Machine Update. 3. Persist minimal: nur Transitions in <code>alarm</code> / <code>alarm_event</code> (nicht jede Messung). 4. Publish: WebSocket/SSE + MQTT bei State-Change (PENDING\u2192FIRING, FIRING\u2192RESOLVED, ACKED \u2026).</p> <p>Sekund\u00e4r (Worker, z. B. alle 30 s): No-Data/L\u00fccken, Recovery-Checks (z. B. nach Neustart, leerem Cache).</p> <p>Warum so? Vermeidet teure \"scan last N minutes per sensor\"-Queries; DB-Reads nur bei Cache-Miss/Invalidation; Historie/Analytics via Timescale Continuous Aggregates.</p>"},{"location":"content/arc/components/alarm/alarm/#5-caching-verteilung","title":"5) Caching &amp; Verteilung","text":"<ul> <li>Single-Instance: in-proc LRU/TTL Cache (z.\u202fB. <code>cachetools</code>).</li> <li>Multi-Instance: Postgres\u2011gest\u00fctztes <code>alarm_state</code> + <code>SELECT \u2026 FOR UPDATE SKIP LOCKED</code> bei Workern.</li> <li>Invalidation: Postgres LISTEN/NOTIFY (<code>rule_changes</code>).</li> </ul>"},{"location":"content/arc/components/alarm/alarm/#6-dedupe-grouping-silences","title":"6) Dedupe, Grouping, Silences","text":"<ul> <li>Dedupe-Key: <code>user_id:storage_id:sensor_id:rule_id</code> \u21d2 eine aktive Instanz.</li> <li>Grouping: FE/Notifications b\u00fcndeln pro Storage\u2011Alarm (z.\u202fB. ein \u201eStorm\u201c-Alarm mit Liste betroffener Sensoren).</li> <li>Silences &amp; Maintenance-Windows: zeitgesteuertes Muten (UI\u2011freundlich). Best Practices angelehnt an Alertmanager.</li> </ul>"},{"location":"content/arc/components/alarm/alarm/#7-endpoints","title":"7) Endpoints","text":"<p>Realtime: <code>GET /stream/alarms</code> (SSE) oder <code>WS /ws/alarms</code> \u2013 Push von State\u2011Changes (keyed by user_id).</p> <p>Alarm-Verwaltung: - <code>GET /alarms/active?storage_id&amp;sensor_id&amp;severity&amp;limit&amp;cursor</code> - <code>GET /alarms/history?from&amp;to&amp;...</code> (paginierbar) - <code>GET /alarms/{id}</code> - <code>POST /alarms/{id}/ack</code> (optional: note) - <code>POST /silences</code> / <code>DELETE /silences/{id}</code> - <code>GET /rules?storage_id|sensor_id</code> - <code>POST /rules</code> / <code>PATCH /rules/{id}</code> (dwell/hysterese/cooldown \u2026) - <code>POST /alarms/test</code> (synthetischer Trigger)</p>"},{"location":"content/arc/components/alarm/alarm/#8-pseudocode-ingest-pfad","title":"8) Pseudocode (Ingest-Pfad)","text":"<pre><code>def on_measurement(sensor_id, ts, value):\n    rule = rule_cache.get(sensor_id)  # reload via LISTEN/NOTIFY on change\n    if not rule or not rule.enabled or in_maintenance(rule, ts) or is_silenced(rule, ts):\n        return\n\n    st = state_cache.get((sensor_id, rule.id)) or State(\"OK\")\n    bounds = (rule.min_value, rule.max_value)\n\n    if value &lt; bounds[0] or value &gt; bounds[1]:\n        if st.state == \"OK\":\n            st.state = \"PENDING\"; st.pending_since = ts\n        elif st.state == \"PENDING\" and ts - st.pending_since &gt;= rule.dwell_seconds:\n            if now() &gt;= (st.cooldown_until or ts):\n                fire_alarm(rule, sensor_id, ts, value)   # create/update 'alarm'\n                st.state = \"FIRING\"\n    else:\n        # inside bounds with hysteresis check\n        if st.state in (\"PENDING\", \"FIRING\"):\n            if is_inside_with_hysteresis(value, rule):\n                if st.state == \"PENDING\":\n                    st.state = \"OK\"; st.pending_since = None\n                elif st.state == \"FIRING\":\n                    resolve_alarm(rule, sensor_id, ts, value)\n                    st.state = \"OK\"; st.cooldown_until = now() + rule.cooldown_seconds\n\n    st.last_value, st.last_ts = value, ts\n    state_cache[(sensor_id, rule.id)] = st\n</code></pre>"},{"location":"content/arc/components/alarm/alarm/#9-sequenzdiagramme","title":"9) Sequenzdiagramme","text":"<p>1) Ausl\u00f6sung (PENDING \u2192 FIRING) </p> <p>2) Aufl\u00f6sung (FIRING \u2192 RESOLVED) </p>"},{"location":"content/arc/components/alarm/alarm/#quellen","title":"Quellen","text":"<ul> <li>[1] [Google SRE Book \u2013 Monitoring Distributed Systems] https://sre.google/sre-book/monitoring-distributed-systems/</li> <li>[2] [Google SRE Book \u2013 Practical Alerting] https://sre.google/sre-book/practical-alerting/</li> <li>[3] [Prometheus Alertmanager \u2013 Overview] https://prometheus.io/docs/alerting/latest/alertmanager/</li> <li>[4] [Prometheus Alertmanager \u2013 Configuration] https://prometheus.io/docs/alerting/latest/configuration/</li> <li>[5] [PostgreSQL \u2013 LISTEN] https://www.postgresql.org/docs/current/sql-listen.html</li> <li>[6] [PostgreSQL \u2013 NOTIFY] https://www.postgresql.org/docs/current/sql-notify.html</li> <li>[7] [TimescaleDB \u2013 Continuous Aggregates (Guide)] https://docs.timescale.com/use-timescale/latest/continuous-aggregates/</li> <li>[8] [TimescaleDB \u2013 About Continuous Aggregates] https://docs.timescale.com/use-timescale/latest/continuous-aggregates/about-continuous-aggregates/</li> <li>[9] [OASIS \u2013 MQTT v5.0 Specification] https://docs.oasis-open.org/mqtt/mqtt/v5.0/mqtt-v5.0.html</li> <li>[10] [HiveMQ \u2013 MQTT Essentials Part 6: QoS Levels] https://www.hivemq.com/blog/mqtt-essentials-part-6-mqtt-quality-of-service-levels/</li> <li>[11] [HiveMQ \u2013 MQTT Essentials Part 8: Retained Messages] https://www.hivemq.com/blog/mqtt-essentials-part-8-retained-messages/</li> <li>[12] [MDN \u2013 Server-Sent Events (EventSource)] https://developer.mozilla.org/en-US/docs/Web/API/EventSource</li> <li>[13] [WHATWG \u2013 HTML Living Standard: Server-sent events] https://html.spec.whatwg.org/multipage/server-sent-events.html</li> </ul>"},{"location":"content/arc/constraints/misc/","title":"Shared-Logging","text":""},{"location":"content/arc/constraints/misc/#1-uberblick-log-level","title":"1. \u00dcberblick &amp; Log-Level","text":"<p><code>configure_logging()</code> initialisiert den Root-Logger zentral:</p> <ul> <li>LOG_LEVEL steuerbar \u00fcber Umgebungsvariable <code>LOG_LEVEL</code> (Standard: <code>INFO</code>)</li> <li>Meldungen unter <code>ERROR</code> (<code>INFO</code> &amp; <code>WARNING</code>) \u2192 stdout</li> <li>Meldungen ab <code>ERROR</code> \u2192 stderr</li> <li>RotatingFileHandler rotiert die Logdatei (<code>app.log</code>) nach konfigurierbarer Gr\u00f6\u00dfe und beh\u00e4lt bis zu f\u00fcnf Backups</li> </ul> <pre><code>export LOG_LEVEL=DEBUG\nexport LOG_FILE=myapp.log\nexport LOG_MAX_BYTES=5242880      # 5 MB\nexport LOG_BACKUP_COUNT=3\n</code></pre>"},{"location":"content/arc/constraints/misc/#2-strukturierte-logs-json","title":"2. Strukturierte Logs (JSON)","text":"<p>Alle Log-Eintr\u00e4ge werden \u00fcber structlog als JSON ausgegeben. Automatisch erg\u00e4nzt um:</p> <ul> <li><code>timestamp</code> (ISO-Format)</li> <li><code>level</code> (INFO, WARNING, ERROR, \u2026)</li> <li>benannte Felder wie <code>event</code>, <code>method</code>, <code>path</code>, <code>duration</code></li> </ul> <p>Beispiel:</p> <pre><code>{\n  \"event\": \"http_request\",\n  \"method\": \"GET\",\n  \"path\": \"/users\",\n  \"status_code\": 200,\n  \"duration\": \"0.0045s\",\n  \"level\": \"info\",\n  \"timestamp\": \"2025-07-31T14:35:22.123Z\"\n}\n</code></pre>"},{"location":"content/arc/constraints/misc/#3-http-request-middleware","title":"3. HTTP-Request-Middleware","text":"<p>Die Funktion <code>add_request_middleware(app: FastAPI)</code> bindet eine Middleware ein, die bei jedem Request automatisch loggt:</p> <pre><code>from backend.src.app.src.shared.logger import add_request_middleware\nfrom fastapi import FastAPI\n\napp = FastAPI()\nadd_request_middleware(app)\n</code></pre>"},{"location":"content/arc/constraints/misc/#geloggte-felder-pro-request","title":"Geloggte Felder pro Request","text":"<ul> <li>HTTP-Methode (<code>request.method</code>)</li> <li>Pfad (<code>request.url.path</code>)</li> <li>Status-Code (<code>response.status_code</code>)</li> <li>Dauer (<code>duration</code> in Sekunden)</li> </ul>"},{"location":"content/arc/constraints/misc/#4-schnellstart-inbetriebnahme","title":"4. Schnellstart (Inbetriebnahme)","text":"<p>Damit das Shared-Logging sofort aktiv ist, f\u00fchrt man diese Schritte in dem Hauptskript (z.B. <code>main.py</code> oder <code>app.py</code>) aus:</p> <pre><code>from fastapi import FastAPI\nfrom backend.src.app.src.shared.logger import get_logger, add_request_middleware, configure_logging\n\n# 1) Globale Logging-Konfiguration aktivieren\nconfigure_logging()\n\n# 2) FastAPI-Anwendung erstellen\napp = FastAPI()\n\n# 3) Request-Middleware anh\u00e4ngen (automatisches Protokollieren aller HTTP-Requests)\nadd_request_middleware(app)\n\n# 4) Logger f\u00fcr dieses Modul holen und einen Start-Eintrag schreiben\n_logger = get_logger(__name__)\n_logger.info(\"Application startup complete\")\n</code></pre>"},{"location":"content/arc/constraints/misc/#erklarung-der-schritte","title":"Erkl\u00e4rung der Schritte","text":"<ol> <li> <p>configure_logging()    Initialisiert die zentralen Logging-Handler (Konsole, Datei, optional ELK) und stellt das JSON-Format \u00fcber structlog bereit.</p> </li> <li> <p>FastAPI()    Erstellt die Instanz der FastAPI-Anwendung, an welche die Middleware angebunden wird.</p> </li> <li> <p>add_request_middleware(app)    Registriert eine Middleware, die bei jeder Anfrage automatisch HTTP-Methode, Pfad, Statuscode und Bearbeitungsdauer in das Log schreibt.</p> </li> <li> <p>get_logger(name)    Stellt einen strukturierten Logger f\u00fcr das aktuelle Modul bereit. Damit k\u00f6nnen anwendungsweit konsistente Log-Eintr\u00e4ge (z.B. mittels <code>logger.info(...)</code>) erzeugt werden.</p> </li> </ol>"},{"location":"content/arc/constraints/techstack/","title":"Technologien","text":""},{"location":"content/arc/constraints/techstack/#frontend","title":"Frontend","text":"<p>Die Anwendung wird als Webanwendung umgesetzt, die in einem Browser l\u00e4uft.  Dies hat mehrere Vorteile:</p> <ul> <li>Plattformunabh\u00e4ngigkeit: Die Anwendung l\u00e4uft auf jedem Ger\u00e4t mit einem modernen Webbrowser, unabh\u00e4ngig vom Betriebssystem (Windows, macOS, Linux, Android, iOS).</li> <li>Einfache Verteilung: Nutzer m\u00fcssen keine Software installieren, sondern k\u00f6nnen die Anwendung direkt \u00fcber eine URL aufrufen.</li> <li>Zug\u00e4nglichkeit: Die Anwendung ist von \u00fcberall aus zug\u00e4nglich, solange eine Internetverbindung besteht.</li> <li>Responsive Design: Die Anwendung kann so gestaltet werden, dass sie auf verschiedenen Bildschirmgr\u00f6\u00dfen (PC, Smartphone) gut aussieht und funktioniert.</li> <li>Zukunftssicherheit: Webanwendungen sind zukunftssicher, da sie nicht an ein bestimmtes Betriebssystem gebunden sind und sich leicht an neue Technologien anpassen lassen.</li> <li>Einfache Updates: Updates k\u00f6nnen zentral auf dem Server durchgef\u00fchrt werden, ohne dass die Nutzer etwas installieren m\u00fcssen.</li> </ul> <p>Die Frontend-Entwicklung erfolgt mit dem Framework React.  Dies ergab sich nach dem Vergleich der popul\u00e4rsten Frontend-Frameworks: React, Vue.js und Angular [1] [2] [3] [4].</p> Kriterium React Vue.js Angular Grundkonzept Eine flexible UI-Bibliothek mit einem gro\u00dfen \u00d6kosystem; Baut auf wiederverwendbaren Komponenten auf. Ein leichtgewichtiges Framework, das f\u00fcr seine Einfachheit bekannt ist. Ein umfassendes Framework f\u00fcr gro\u00dfe, strukturierte (Enterprise)-Anwendungen. Performance Sehr hoch. Nutzt einen virtuellen DOM f\u00fcr schnelle und effiziente Updates der Benutzeroberfl\u00e4che. Sehr hoch. Gilt als sehr performant und leichtgewichtig, was zu schnellen Ladezeiten f\u00fchrt. Gut. F\u00fcr gro\u00dfe Anwendungen optimiert, kann aber durch seine Gr\u00f6\u00dfe einen h\u00f6heren Initialaufwand haben. Lernkurve Mittel. Die Grundlagen sind schnell gelernt, Bestimmte Konzepte wie State-Management erfordern aber Einarbeitung. Niedrig. Gilt als das am einfachsten zu lernende Framework, ideal f\u00fcr Einsteiger und Projekte mit schneller Entwicklungszeit. Hoch. Erfordert das Verst\u00e4ndnis einer komplexen, festen Architektur. Community &amp; \u00d6kosystem Sehr gro\u00df. Die mit Abstand gr\u00f6\u00dfte Community, unz\u00e4hlige Tutorials, fertige L\u00f6sungen und Tools. Gro\u00df. Eine gr\u00f6\u00dfere Community mit vielen Plugins. Gro\u00df. Starker R\u00fcckhalt durch Google und eine gro\u00dfe Enterprise-Community. UI Projekt-Eignung Sehr gut. Sehr gro\u00dfe Auswahl an spezialisierten Charting-Bibliotheken \\(z\\.B\\. Recharts, Victory\\) und UI-Komponenten. Gut. Bietet ebenfalls gute Bibliotheken \\(z\\.B\\. vue\\-echarts\\) und eine reaktive Datenbindung, die f\u00fcr Dashboards ideal ist. Gut. Bietet ebenfalls Bibliotheken, die feste Struktur kann aber bei sehr individuellen Visualisierungen hinderlich sein. <p>Die Evaluation der Frontend-Frameworks ergab, dass React die beste Wahl f\u00fcr die Anwendung ist.  Die Vorteile liegen hier vor allem in der Flexibilit\u00e4t und dem riesigen \u00d6kosystem.  So sind f\u00fcr viele (projektgegebene) Anwendungsf\u00e4lle fertige Bibliothek gegeben, insbesondere f\u00fcr Datenvisualisierung und Dashboards.  Die komponentenbasierte Architektur f\u00f6rdert weiter die Wiederverwendbarkeit von Code, sodass z.B. ein Sensor-Widget einmal gebaut und mehrfach verwendet werden kann.</p>"},{"location":"content/arc/constraints/techstack/#nextjs-5","title":"Next.js [5]","text":"<p>F\u00fcr die Umsetzung der Anwendung wird Next.js als Framework f\u00fcr React gew\u00e4hlt.  Next.js ist ein beliebtes Framework, das auf React aufbaut und zus\u00e4tzliche Funktionen wie Server-Side Rendering (SSR), statische Seitengenerierung (SSG) und API-Routen bietet.  Dadurch vereinfacht es die Entwicklung von Webanwendungen und bietet eine bessere Performance. </p>"},{"location":"content/arc/constraints/techstack/#backend","title":"Backend","text":"<p>Die Anwendung wird mit der Programmiersprache Python entwickelt.  Hierf\u00fcr lassen sich insbesondere folgende Vorteile anf\u00fchren:</p> <ul> <li>Python ist eine weit verbreitete Sprache, die sich mit seinen Frameworks gut f\u00fcr Webanwendungen eignet.</li> <li>Python hat eine gro\u00dfe Community und viele Bibliotheken, die die Entwicklung erleichtern.</li> <li>Python ist im Team bereits gut bekannt, was die Einarbeitungszeit reduziert.</li> <li>Python erm\u00f6glicht aufgrund seiner Einfachheit eine schnelle Entwicklung und Anpassung (z.B. sp\u00e4tere Erweiterung) der Anwendung.</li> </ul> <p>Als Framework f\u00fcr den Backend-Teil der Anwendung wird FastAPI gew\u00e4hlt. Dies ergab sich nach dem Vergleich der popul\u00e4rsten Frameworks, die f\u00fcr die Entwicklung von Webanwendungen in Python geeignet sind: FastAPI, Flask und Django [6] [7] [8].</p> Kriterium FastAPI Flask Django Grundkonzept Modernes, hochperformantes, leichtgewichtiges API-Framework. Kompaktes Framework, das sich auf das Wesentliche konzentriert. Umfassendes, komplexes Full-Stack-Framework f\u00fcr gro\u00dfe Webanwendungen. Performance Sehr gut. Eines der schnellsten Python-Frameworks, da es auf Starlette und Pydantic basiert. Zudem arbeitet es asynchron. Gut. Als Micro-Framework sehr schlank, die Gesamtperformance h\u00e4ngt aber stark von den gew\u00e4hlten Erweiterungen ab. Gut. F\u00fcr Webanwendungen sehr performant, aber m\u00f6glicherweise erst nach umfassender Konfiguration bzw Optimierung. Erweiterbarkeit Sehr gut. Das moderne Design und die automatische API-Dokumentation (Swagger) erleichtern die Anbindung neuer Module und externer Dienste. Sehr gut. Das ist die Kernst\u00e4rke von Flask - modular bindet man nur das ein, was man braucht und hat die volle Kontrolle. Gut. Besitzt ein ausgereiftes App-Konzept - die feste Struktur kann die Flexibilit\u00e4t und Schnelligkeit in der Entwicklung aber einschr\u00e4nken. Lernkurve Niedrig/Mittel. Die Grundlagen sind schnell gelernt, die asynchrone Programmierung erfordert (ohne Vorwissen) Einarbeitung. Niedrig. Gilt als das am einfachsten zu lernende Framework, ideal f\u00fcr Einsteiger und kleinere Projekte. Hoch. Die F\u00fclle an integrierten Konzepten und Features erfordert eine l\u00e4ngere Einarbeitungszeit. Integrierte Features Wenige. Fokussiert auf API-Erstellung, Datenvalidierung und Dokumentation. Alles Weitere wird flexibel mit Bibliotheken erg\u00e4nzt. Sehr wenige. Bringt nur einen Webserver und Routing mit. Datenbanken, Nutzerverwaltung etc. m\u00fcssen selbst gew\u00e4hlt werden. Sehr viele. Integrierter ORM (Datenbankzugriff), Nutzerverwaltung, Admin-Oberfl\u00e4che, Sicherheitsfunktionen etc.. IoT-Kompatibilit\u00e4t Sehr gut. Nativ asynchron und so somit sehr gut f\u00fcr die parallele Verarbeitung von Sensor-Daten und Echtzeit-Kommunikation geeignet.  Es lassen sich problemlos ankommende Daten verarbeiten, w\u00e4hrend weitere Prozesse (bspw. Anfragen vom Frontend) nicht blockiert werden. Gut. Ben\u00f6tigt Erweiterungen (z.B. Flask-SocketIO), ist aber gut anpassbar. Gut. Asynchronit\u00e4t wird \u00fcber eine zus\u00e4tzliche Schicht (\"Django Channels\") realisiert und ist nicht im Kern verankert. <p>Die Evaluation der Backend-Frameworks ergab, dass FastAPI die beste Wahl f\u00fcr die Anwendung ist.  Zum einen ist FastAPI leichtgewichtig, performant und basiert nativ auf einer sehr asynchronen Architektur, die f\u00fcr die parallele Verarbeitung von IoT-Daten, aber auch f\u00fcr die Bedienung eines Frontends, geeignet ist. So kann die Anwendung verschiedene Aufgaben gleichzeitig und ohne Blockierung der Anwendungs-Worker erledigen.  Zum anderen ist FastAPI sehr gut erweiterbar, was die Anbindung neuer Module erleichtert.  Die automatisch generierte API-Dokumentation (\u00fcber Swagger) beschleunigt weiter die Entwicklung und verbessert die Wartbarkeit der Anwendung.</p>"},{"location":"content/arc/constraints/techstack/#frontend-integration","title":"Frontend-Integration","text":"<p>Hinsichtlich der Frontend-Kompatibilit\u00e4t ist FastAPI f\u00fcr eine entkoppelte Architektur ausgelegt.  Es fungiert als reine API-Schnittstelle und kann mit jedem modernen (JavaScript-)Framework wie React kommunizieren.  Dies erm\u00f6glicht eine klare Trennung zwischen der Benutzeroberfl\u00e4che und der Logik im Backend, was die Entwicklung (und Skalierbarkeit) des Gesamtsystems vereinfacht.</p> <p>Quellen:</p> <ul> <li>[1] Top 7 Frontend Frameworks to Use in 2025: Pro Advice</li> <li>[2] Angular vs React vs Vue: Which Framework Should You Choose in 2025?</li> <li>[3] The Ultimate Frontend Battle</li> <li>[4] Top 20 Frontend Development Frameworks 2025</li> <li>[5] Next.js vs React? It\u2019s a Partnership, Not a Competition</li> <li>[6] Comparison of FastAPI with Django and Flask</li> <li>[7] Which Is the Best Python Web Framework: Django, Flask, or FastAPI?</li> <li>[8] 2025's Top 10 Python Web Frameworks Compared</li> </ul>"},{"location":"content/audit/SFMEA/","title":"SFMEA","text":""},{"location":"content/audit/SFMEA/#software-fmea-analyse","title":"Software-FMEA Analyse","text":"<p>Folgende SFMEA-Analyse dient der Identifizierung potenzieller Schwachstellen des Systems - insbesondere des oben beschriebenen MVPs: Daf\u00fcr wird das Gesamtsystem STORASENSE in seine Teilsysteme gegliedert und analysiert:</p>"},{"location":"content/audit/SFMEA/#legende","title":"Legende:","text":"<p>Bedeutung (B): Auswirkung des Fehlers (1 = keine Auswirkung, 10 = totaler Schaden)</p> <p>Auftreten (A): Wahrscheinlichkeit des Auftretens der Ursache (1 = sehr unwahrscheinlich, 10 = sehr wahrscheinlich)</p> <p>Entdeckung (E): Wahrscheinlichkeit, dass der Fehler entdeckt wird, bevor er Schaden anrichtet (1 = sehr wahrscheinlich entdeckt, 10 = nicht zu entdecken)</p> <p>Risikopriorit\u00e4tszahl (RPZ): B \u00d7 A \u00d7 E (hoher Wert = Handlungsbedarf)</p>"},{"location":"content/audit/SFMEA/#1-storasense-sensoric-sensor-einheit-hardware","title":"1. STORASENSE-SENSORIC: Sensor-Einheit (Hardware):","text":"<p>Verantwortlich f\u00fcr die Erfassung der physikalischen Messwerte.</p> Fehlerm\u00f6glichkeit Fehlerauswirkung B Fehlerursache A Ma\u00dfnahmen E RPZ Sensor liefert dauerhaft falsche Werte Falsche Daten werden gespeichert; Alarme werden f\u00e4lschlicherweise ausgel\u00f6st oder gar nicht. 9 Sensor defekt oder Programmierfehler beim Auslesen. 4 Plausibilit\u00e4ts-Checks im Backend (z.B. Temperatur springt nicht von 10\u00b0C auf 50\u00b0C). Implementierung von Algorithmen zur Ausrei\u00dfer-Erkennung 5 180 Mikrocontroller (Arduino) friert ein Keine neuen Messwerte werden mehr gesendet und \u00dcberwachung f\u00e4llt komplett aus. 10 Software-Bug (z.B. Endlosschleife) oder Speicher\u00fcberlauf. 3 Hardware-Watchdog-Timer, der den Arduino automatisch neu startet (vgl. NF-Req Verf\u00fcgbarkeit). Einsatz eines robusten Watchdog-Timers. 2 60 Verlust der WLAN-Verbindung Keine neuen Messwerte werden an den MQTT-Broker gesendet. 8 WLAN-Router ausgefallen oder falsches Passwort. 5 Implementierte Wiederverbindungs-Logik auf dem Mikrocontroller (vgl. NF-Req Verf\u00fcgbarkeit). Backend \u00fcberwacht den Zeitstempel der letzten Nachricht pro Sensor und l\u00f6st einen \"Verbindungsverlust\"-Alarm aus. 3 120"},{"location":"content/audit/SFMEA/#2-storasense-platform-backend-fastapi-anwendung","title":"2. STORASENSE-PLATFORM: Backend (FastAPI-Anwendung)","text":"<p>Verantwortlich f\u00fcr die Datenverarbeitung, Speicherung, Alarmierung und API-Bereitstellung.</p> Fehlerm\u00f6glichkeit Fehlerauswirkung B Fehlerursache A Ma\u00dfnahmen E RPZ FastAPI-Anwendung st\u00fcrzt ab Das gesamte System ist offline. 10 Unbehandelter Fehler im Code (z.B. TypeError). 4 Einsatz eines Prozess-Managers (z.B. systemd), der die Anwendung bei einem Absturz automatisch neu startet. Implementierung eines zentralen Logging-Systems (zur Analyse der Absturzursache) und Einrichten eines HEALTH-API-Endpunktes. 2 80 Verbindung zur Datenbank (MongoDB/SQLite) geht verloren Eingehende Messwerte k\u00f6nnen nicht gespeichert werden; Nutzer k\u00f6nnen sich nicht anmelden oder Daten abrufen. 8 Datenbank-Server ist offline; Netzwerkproblem bzw Docker-Problem; falsche Zugangsdaten. 3 Fehlerbehandlung (try-except Exception Handling) im Code; Wiederverbindungs-Logik im Datenbanktreiber. 4 96 Alarm wird nicht ausgel\u00f6st Ein kritischer Zustand (z.B. zu hohe Temperatur) wird erkannt, aber der Nutzer wird nicht benachrichtigt. Der Schaden passiert. 10 Fehler im Alarmierungs-Code; externer E-Mail/Push-Dienst ist ausgefallen; falsche Konfiguration. 2 Unit-Tests f\u00fcr die Alarm-Logik. 6 120 Unbefugter Zugriff auf API (Authentifizierungsfehler) Ein anonymer Angreifer kann gesch\u00fctzte Daten auslesen oder schreibend ver\u00e4ndern. Kompromittierung der Datensicherheit. 9 API-Endpunkt ist nicht gesch\u00fctzt; schwache Passwort-Richtlinien; kein Schutz vor Brute-Force-Angriffen. 5 Implementierung von OAuth2 mit JWT-Tokens f\u00fcr jeden gesch\u00fctzten Endpunkt; Sicheres Passwort-Hashing 3 135 Unberechtigter Zugriff auf Daten (Autorisierungsfehler) Ein angemeldeter Nutzer greift auf Daten zu, f\u00fcr die er keine Berechtigung hat (z.B. Daten eines anderen Nutzers). 8 Fehlerhafte oder fehlende Pr\u00fcfung der Benutzerrolle oder des Datenbesitzes innerhalb der API-Logik. 4 Implementierung einer rollenbasierten Zugriffskontrolle (RBAC); API-Logik pr\u00fcft bei jeder Anfrage, ob der Nutzer die erforderliche Rolle (Admin, User) hat. 4 128"},{"location":"content/audit/auth/","title":"Auth","text":"<ul> <li>https://tinyauth.app/docs/getting-started</li> <li>https://www.xda-developers.com/reasons-use-tinyauth-instead-of-authelia-for-home-lab/</li> </ul>"}]}